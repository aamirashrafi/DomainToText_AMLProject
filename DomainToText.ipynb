{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DomainToText.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "LrFXzm3vj6fk",
        "-dWA-jixJ5Ms",
        "uJJPZE_JkBuH",
        "2BXkS0wS2ci7",
        "UCY7uaO7KX8X",
        "YTWi0ahSL5hw"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Mounting Drive"
      ],
      "metadata": {
        "id": "LrFXzm3vj6fk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before start I would like to give a brief about directory structure of projects. Basically we have two projects, one is DomainToText_AMLProject and second one is DescribingTextures. All the files related to DomainToText_AMLProject are under /content/drive/MyDrive/DomainToText_AMLProject directory, and all the files related to DescribingTextures are under /content/drive/MyDrive/DescribingTextureCopy/DescribingTextures directory.\n",
        "For the sake of simplicity and avoiding each time change the path in the code I would prefer 1st to move in the project directory and then run the respective code to train the model."
      ],
      "metadata": {
        "id": "-iuXkC4uHDAW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LacFRD392hQr",
        "outputId": "ad32d30c-e150-4d0c-e069-ad4b99086391"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train DomainToText_AMLProject To Produce the baseline"
      ],
      "metadata": {
        "id": "-dWA-jixJ5Ms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Moving to the project directory"
      ],
      "metadata": {
        "id": "uJJPZE_JkBuH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cd drive/MyDrive/DomainToText_AMLProject/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8uJPtE47JYj",
        "outputId": "da1fc491-7e2a-4d47-8545-26f6b482f36c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/DomainToText_AMLProject\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Installing Dependencies"
      ],
      "metadata": {
        "id": "KZOS-siakLf7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers==4.11.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0G2Ez6LX64G",
        "outputId": "25f6c39e-51f7-4359-f2a4-1b21f31fe39f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers==4.11.0\n",
            "  Downloading transformers-4.11.0-py3-none-any.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 4.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.11.0) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.11.0) (1.19.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.11.0) (4.62.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.11.0) (3.4.2)\n",
            "Collecting huggingface-hub>=0.0.17\n",
            "  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 5.8 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 47.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.11.0) (2019.12.20)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 47.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.11.0) (21.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.11.0) (4.10.1)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 48.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.17->transformers==4.11.0) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers==4.11.0) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.11.0) (3.7.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.11.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.11.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.11.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.11.0) (2021.10.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.11.0) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.11.0) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.11.0) (1.15.0)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.47 tokenizers-0.10.3 transformers-4.11.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation to reproduce the baselines"
      ],
      "metadata": {
        "id": "2BXkS0wS2ci7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python eval_ensamble.py --path_to_txt \"./data/PACS\" --target \"ArtPainting\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "psVEf5dG26GQ",
        "outputId": "e31cf506-f5a7-4296-9888-60110a5083f4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(gpu=0, num_classes=7, path_to_dataset='./', path_to_txt='./data/PACS', target='ArtPainting')\n",
            "äsdasfs\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Sources Cartoon, Photo, Sketch\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100% 44.7M/44.7M [00:00<00:00, 78.2MB/s]\n",
            "Model of Cartoon loaded \n",
            "Model of Photo loaded \n",
            "Model of Sketch loaded \n",
            "Downloading: \"https://download.pytorch.org/models/resnet101-63fe2227.pth\" to /root/.cache/torch/hub/checkpoints/resnet101-63fe2227.pth\n",
            "100% 171M/171M [00:02<00:00, 80.1MB/s]\n",
            "Downloading: 100% 226k/226k [00:00<00:00, 2.15MB/s]\n",
            "Downloading: 100% 28.0/28.0 [00:00<00:00, 21.8kB/s]\n",
            "Downloading: 100% 455k/455k [00:00<00:00, 3.17MB/s]\n",
            "Downloading: 100% 570/570 [00:00<00:00, 556kB/s]\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/configuration_utils.py:337: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
            "  \"Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 \"\n",
            "Downloading: 100% 420M/420M [00:10<00:00, 42.1MB/s]\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Model pretrained on Textures loaded\n",
            "100% 2344/2344 [02:32<00:00, 15.37it/s]\n",
            "100% 1670/1670 [01:39<00:00, 16.70it/s]\n",
            "100% 3929/3929 [03:55<00:00, 16.66it/s]\n",
            "Evaluation on the Target domain - ArtPainting\n",
            "100% 2048/2048 [03:19<00:00, 10.27it/s]\n",
            "Accuracy mean: 67.63 \n",
            "Accuracy text_domain_embedding: 70.21 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python eval_ensamble.py --path_to_txt \"./data/PACS\" --target \"Cartoon\""
      ],
      "metadata": {
        "id": "I0kzekU411OV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0f1ee6f-6fb9-4518-d7d1-6fa00c1b0c66"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(gpu=0, num_classes=7, path_to_dataset='./', path_to_txt='./data/PACS', target='Cartoon')\n",
            "äsdasfs\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Sources ArtPainting, Photo, Sketch\n",
            "Model of ArtPainting loaded \n",
            "Model of Photo loaded \n",
            "Model of Sketch loaded \n",
            "/usr/local/lib/python3.7/dist-packages/transformers/configuration_utils.py:337: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
            "  \"Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 \"\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Model pretrained on Textures loaded\n",
            "100% 2048/2048 [01:52<00:00, 18.27it/s]\n",
            "100% 1670/1670 [01:32<00:00, 17.98it/s]\n",
            "100% 3929/3929 [03:38<00:00, 18.00it/s]\n",
            "Evaluation on the Target domain - Cartoon\n",
            "100% 2344/2344 [03:36<00:00, 10.85it/s]\n",
            "Accuracy mean: 57.12 \n",
            "Accuracy text_domain_embedding: 57.98 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python eval_ensamble.py --path_to_txt \"./data/PACS\" --target \"Photo\""
      ],
      "metadata": {
        "id": "66sgF_ojOVFR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61b5992e-8a74-44d0-98a4-f4f073894b1b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(gpu=0, num_classes=7, path_to_dataset='./', path_to_txt='./data/PACS', target='Photo')\n",
            "äsdasfs\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Sources ArtPainting, Cartoon, Sketch\n",
            "Model of ArtPainting loaded \n",
            "Model of Cartoon loaded \n",
            "Model of Sketch loaded \n",
            "/usr/local/lib/python3.7/dist-packages/transformers/configuration_utils.py:337: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
            "  \"Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 \"\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Model pretrained on Textures loaded\n",
            "100% 2048/2048 [01:51<00:00, 18.29it/s]\n",
            "100% 2344/2344 [02:09<00:00, 18.12it/s]\n",
            "100% 3929/3929 [03:35<00:00, 18.20it/s]\n",
            "Evaluation on the Target domain - Photo\n",
            "100% 1670/1670 [02:34<00:00, 10.78it/s]\n",
            "Accuracy mean: 94.49 \n",
            "Accuracy text_domain_embedding: 94.85 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python eval_ensamble.py --path_to_txt \"./data/PACS\" --target \"Sketch\""
      ],
      "metadata": {
        "id": "I_Mid-4PRQBJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d82a8651-e77f-47b8-e4d8-edb4a96cd631"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(gpu=0, num_classes=7, path_to_dataset='./', path_to_txt='./data/PACS', target='Sketch')\n",
            "äsdasfs\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Sources ArtPainting, Cartoon, Photo\n",
            "Model of ArtPainting loaded \n",
            "Model of Cartoon loaded \n",
            "Model of Photo loaded \n",
            "/usr/local/lib/python3.7/dist-packages/transformers/configuration_utils.py:337: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
            "  \"Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 \"\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Model pretrained on Textures loaded\n",
            "100% 2048/2048 [01:53<00:00, 18.05it/s]\n",
            "100% 2344/2344 [02:06<00:00, 18.48it/s]\n",
            "100% 1670/1670 [01:29<00:00, 18.58it/s]\n",
            "Evaluation on the Target domain - Sketch\n",
            "100% 3929/3929 [06:02<00:00, 10.85it/s]\n",
            "Accuracy mean: 60.40 \n",
            "Accuracy text_domain_embedding: 62.03 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train DescribingTextures"
      ],
      "metadata": {
        "id": "UCY7uaO7KX8X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Moving To Project Directory"
      ],
      "metadata": {
        "id": "YTWi0ahSL5hw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After successful traing of DomainToText_AMLProject model we have to train another model(DescribingTextures) by replacing our dataset(PACS) and corresponding image description. In order to train this model we are moving to DescribingTextures Project Directory"
      ],
      "metadata": {
        "id": "M4pKj5BklQLe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cd ../DescribingTextureCopy/DescribingTextures/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RMe1RLlbl-I1",
        "outputId": "90f08b74-2eb5-4824-90a2-93b48e0a62d5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/DescribingTextureCopy/DescribingTextures\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before training this model we have to set 'bert' as sentence encoder, and replace manually created image description and image split files image_descriptions.json and image_splits.json. and then we have to install the dependencies to train this model."
      ],
      "metadata": {
        "id": "7zbr4R0CmvU4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Installing Dependencies"
      ],
      "metadata": {
        "id": "kZkn8bbFMLxD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install yacs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kup0Hu37msb7",
        "outputId": "994d75db-22d2-4730-b3db-b865d39540a6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting yacs\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from yacs) (3.13)\n",
            "Installing collected packages: yacs\n",
            "Successfully installed yacs-0.1.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install allennlp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QATZdmUkmaQJ",
        "outputId": "ec713263-9b93-4cb3-c5de-b5048c6313bc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting allennlp\n",
            "  Downloading allennlp-2.9.0-py3-none-any.whl (716 kB)\n",
            "\u001b[?25l\r\u001b[K     |▌                               | 10 kB 22.7 MB/s eta 0:00:01\r\u001b[K     |█                               | 20 kB 26.2 MB/s eta 0:00:01\r\u001b[K     |█▍                              | 30 kB 21.1 MB/s eta 0:00:01\r\u001b[K     |█▉                              | 40 kB 17.8 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 51 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 61 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 71 kB 11.9 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 81 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 92 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 102 kB 12.0 MB/s eta 0:00:01\r\u001b[K     |█████                           | 112 kB 12.0 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 122 kB 12.0 MB/s eta 0:00:01\r\u001b[K     |██████                          | 133 kB 12.0 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 143 kB 12.0 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 153 kB 12.0 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 163 kB 12.0 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 174 kB 12.0 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 184 kB 12.0 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 194 kB 12.0 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 204 kB 12.0 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 215 kB 12.0 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 225 kB 12.0 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 235 kB 12.0 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 245 kB 12.0 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 256 kB 12.0 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 266 kB 12.0 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 276 kB 12.0 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 286 kB 12.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 296 kB 12.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 307 kB 12.0 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 317 kB 12.0 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 327 kB 12.0 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 337 kB 12.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 348 kB 12.0 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 358 kB 12.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 368 kB 12.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 378 kB 12.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 389 kB 12.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 399 kB 12.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 409 kB 12.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 419 kB 12.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 430 kB 12.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 440 kB 12.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 450 kB 12.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 460 kB 12.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 471 kB 12.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 481 kB 12.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 491 kB 12.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 501 kB 12.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 512 kB 12.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 522 kB 12.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 532 kB 12.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 542 kB 12.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 552 kB 12.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 563 kB 12.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 573 kB 12.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 583 kB 12.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 593 kB 12.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 604 kB 12.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 614 kB 12.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 624 kB 12.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 634 kB 12.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 645 kB 12.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 655 kB 12.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 665 kB 12.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 675 kB 12.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 686 kB 12.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 696 kB 12.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 706 kB 12.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 716 kB 12.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.62 in /usr/local/lib/python3.7/dist-packages (from allennlp) (4.62.3)\n",
            "Collecting wandb<0.13.0,>=0.10.0\n",
            "  Downloading wandb-0.12.10-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 44.3 MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 34.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: more-itertools in /usr/local/lib/python3.7/dist-packages (from allennlp) (8.12.0)\n",
            "Collecting checklist==0.0.11\n",
            "  Downloading checklist-0.0.11.tar.gz (12.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.1 MB 20.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: lmdb in /usr/local/lib/python3.7/dist-packages (from allennlp) (0.99)\n",
            "Requirement already satisfied: nltk<3.6.6 in /usr/local/lib/python3.7/dist-packages (from allennlp) (3.2.5)\n",
            "Requirement already satisfied: torchvision<0.12.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from allennlp) (0.11.1+cu111)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from allennlp) (3.6.4)\n",
            "Collecting huggingface-hub>=0.0.16\n",
            "  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor==1.1.0 in /usr/local/lib/python3.7/dist-packages (from allennlp) (1.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from allennlp) (3.1.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from allennlp) (1.0.2)\n",
            "Requirement already satisfied: torch<1.11.0,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from allennlp) (1.10.0+cu111)\n",
            "Collecting transformers<4.16,>=4.1\n",
            "  Downloading transformers-4.15.0-py3-none-any.whl (3.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4 MB 43.6 MB/s \n",
            "\u001b[?25hCollecting fairscale==0.4.5\n",
            "  Downloading fairscale-0.4.5.tar.gz (240 kB)\n",
            "\u001b[K     |████████████████████████████████| 240 kB 28.4 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: spacy<3.3,>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from allennlp) (2.2.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from allennlp) (1.19.5)\n",
            "Collecting tensorboardX>=1.2\n",
            "  Downloading tensorboardX-2.4.1-py2.py3-none-any.whl (124 kB)\n",
            "\u001b[K     |████████████████████████████████| 124 kB 47.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.18 in /usr/local/lib/python3.7/dist-packages (from allennlp) (2.23.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from allennlp) (0.3.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from allennlp) (1.4.1)\n",
            "Collecting jsonnet>=0.10.0\n",
            "  Downloading jsonnet-0.18.0.tar.gz (592 kB)\n",
            "\u001b[K     |████████████████████████████████| 592 kB 52.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock<3.5,>=3.3 in /usr/local/lib/python3.7/dist-packages (from allennlp) (3.4.2)\n",
            "Collecting cached-path<2.0.0,>=1.0.2\n",
            "  Downloading cached_path-1.0.2-py3-none-any.whl (26 kB)\n",
            "Collecting base58\n",
            "  Downloading base58-2.1.1-py3-none-any.whl (5.6 kB)\n",
            "Collecting munch>=2.5\n",
            "  Downloading munch-2.5.0-py2.py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: jupyter>=1.0 in /usr/local/lib/python3.7/dist-packages (from checklist==0.0.11->allennlp) (1.0.0)\n",
            "Requirement already satisfied: ipywidgets>=7.5 in /usr/local/lib/python3.7/dist-packages (from checklist==0.0.11->allennlp) (7.6.5)\n",
            "Collecting patternfork-nosql\n",
            "  Downloading patternfork_nosql-3.6.tar.gz (22.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 22.3 MB 1.4 MB/s \n",
            "\u001b[?25hCollecting iso-639\n",
            "  Downloading iso-639-0.4.5.tar.gz (167 kB)\n",
            "\u001b[K     |████████████████████████████████| 167 kB 49.4 MB/s \n",
            "\u001b[?25hCollecting boto3<2.0,>=1.0\n",
            "  Downloading boto3-1.20.52-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 49.4 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub>=0.0.16\n",
            "  Downloading huggingface_hub-0.2.1-py3-none-any.whl (61 kB)\n",
            "\u001b[K     |████████████████████████████████| 61 kB 528 kB/s \n",
            "\u001b[?25hRequirement already satisfied: google-cloud-storage<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from cached-path<2.0.0,>=1.0.2->allennlp) (1.18.1)\n",
            "Collecting botocore<1.24.0,>=1.23.52\n",
            "  Downloading botocore-1.23.52-py3-none-any.whl (8.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.5 MB 40.7 MB/s \n",
            "\u001b[?25hCollecting s3transfer<0.6.0,>=0.5.0\n",
            "  Downloading s3transfer-0.5.1-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 5.9 MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.24.0,>=1.23.52->boto3<2.0,>=1.0->cached-path<2.0.0,>=1.0.2->allennlp) (2.8.2)\n",
            "Collecting urllib3<1.27,>=1.25.4\n",
            "  Downloading urllib3-1.26.8-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 43.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-auth>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage<2.0,>=1.0->cached-path<2.0.0,>=1.0.2->allennlp) (1.35.0)\n",
            "Requirement already satisfied: google-resumable-media<0.5.0dev,>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage<2.0,>=1.0->cached-path<2.0.0,>=1.0.2->allennlp) (0.4.1)\n",
            "Requirement already satisfied: google-cloud-core<2.0dev,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage<2.0,>=1.0->cached-path<2.0.0,>=1.0.2->allennlp) (1.0.3)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2.0->google-cloud-storage<2.0,>=1.0->cached-path<2.0.0,>=1.0.2->allennlp) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2.0->google-cloud-storage<2.0,>=1.0->cached-path<2.0.0,>=1.0.2->allennlp) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2.0->google-cloud-storage<2.0,>=1.0->cached-path<2.0.0,>=1.0.2->allennlp) (0.2.8)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2.0->google-cloud-storage<2.0,>=1.0->cached-path<2.0.0,>=1.0.2->allennlp) (57.4.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2.0->google-cloud-storage<2.0,>=1.0->cached-path<2.0.0,>=1.0.2->allennlp) (1.15.0)\n",
            "Requirement already satisfied: google-api-core<2.0.0dev,>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage<2.0,>=1.0->cached-path<2.0.0,>=1.0.2->allennlp) (1.26.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage<2.0,>=1.0->cached-path<2.0.0,>=1.0.2->allennlp) (1.54.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage<2.0,>=1.0->cached-path<2.0.0,>=1.0.2->allennlp) (2018.9)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage<2.0,>=1.0->cached-path<2.0.0,>=1.0.2->allennlp) (3.17.3)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage<2.0,>=1.0->cached-path<2.0.0,>=1.0.2->allennlp) (21.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.16->allennlp) (3.13)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.16->allennlp) (3.10.0.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.16->allennlp) (4.10.1)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.5->checklist==0.0.11->allennlp) (5.5.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.5->checklist==0.0.11->allennlp) (1.0.2)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.5->checklist==0.0.11->allennlp) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.5->checklist==0.0.11->allennlp) (5.1.1)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.5->checklist==0.0.11->allennlp) (3.5.2)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.5->checklist==0.0.11->allennlp) (5.1.3)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.5->checklist==0.0.11->allennlp) (4.10.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.5->checklist==0.0.11->allennlp) (5.3.5)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.5->checklist==0.0.11->allennlp) (5.1.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5->checklist==0.0.11->allennlp) (1.0.18)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5->checklist==0.0.11->allennlp) (2.6.1)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5->checklist==0.0.11->allennlp) (0.8.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5->checklist==0.0.11->allennlp) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5->checklist==0.0.11->allennlp) (0.7.5)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5->checklist==0.0.11->allennlp) (4.8.0)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.7/dist-packages (from jupyter>=1.0->checklist==0.0.11->allennlp) (5.2.2)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from jupyter>=1.0->checklist==0.0.11->allennlp) (5.6.1)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.7/dist-packages (from jupyter>=1.0->checklist==0.0.11->allennlp) (5.3.1)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.7/dist-packages (from jupyter>=1.0->checklist==0.0.11->allennlp) (5.2.0)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets>=7.5->checklist==0.0.11->allennlp) (4.9.1)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets>=7.5->checklist==0.0.11->allennlp) (4.3.3)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets>=7.5->checklist==0.0.11->allennlp) (21.4.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets>=7.5->checklist==0.0.11->allennlp) (0.18.1)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets>=7.5->checklist==0.0.11->allennlp) (5.4.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets>=7.5->checklist==0.0.11->allennlp) (3.7.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<2.0.0dev,>=1.14.0->google-cloud-core<2.0dev,>=1.0.0->google-cloud-storage<2.0,>=1.0->cached-path<2.0.0,>=1.0.2->allennlp) (3.0.7)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipywidgets>=7.5->checklist==0.0.11->allennlp) (0.2.5)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.2.0->google-cloud-storage<2.0,>=1.0->cached-path<2.0.0,>=1.0.2->allennlp) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18->allennlp) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18->allennlp) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18->allennlp) (2.10)\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 37.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3,>=2.1.0->allennlp) (3.0.6)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3,>=2.1.0->allennlp) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3,>=2.1.0->allennlp) (1.0.6)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3,>=2.1.0->allennlp) (1.1.3)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3,>=2.1.0->allennlp) (1.0.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3,>=2.1.0->allennlp) (0.4.1)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3,>=2.1.0->allennlp) (7.4.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3,>=2.1.0->allennlp) (2.0.6)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3,>=2.1.0->allennlp) (0.9.0)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision<0.12.0,>=0.8.1->allennlp) (7.1.2)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 46.3 MB/s \n",
            "\u001b[?25hCollecting pyyaml\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 49.3 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 48.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<4.16,>=4.1->allennlp) (2019.12.20)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb<0.13.0,>=0.10.0->allennlp) (2.3)\n",
            "Collecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.26-py3-none-any.whl (180 kB)\n",
            "\u001b[K     |████████████████████████████████| 180 kB 56.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb<0.13.0,>=0.10.0->allennlp) (7.1.2)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.8-py3-none-any.whl (9.5 kB)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.5.4-py2.py3-none-any.whl (143 kB)\n",
            "\u001b[K     |████████████████████████████████| 143 kB 50.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb<0.13.0,>=0.10.0->allennlp) (5.4.8)\n",
            "Collecting yaspin>=1.0.0\n",
            "  Downloading yaspin-2.1.0-py3-none-any.whl (18 kB)\n",
            "Collecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.8 MB/s \n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter>=1.0->checklist==0.0.11->allennlp) (2.11.3)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter>=1.0->checklist==0.0.11->allennlp) (1.8.0)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter>=1.0->checklist==0.0.11->allennlp) (0.13.1)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets>=7.5->checklist==0.0.11->allennlp) (22.3.0)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook->jupyter>=1.0->checklist==0.0.11->allennlp) (0.7.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->allennlp) (1.5.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->notebook->jupyter>=1.0->checklist==0.0.11->allennlp) (2.0.1)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter>=1.0->checklist==0.0.11->allennlp) (4.1.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter>=1.0->checklist==0.0.11->allennlp) (1.5.0)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter>=1.0->checklist==0.0.11->allennlp) (0.5.0)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter>=1.0->checklist==0.0.11->allennlp) (0.4)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter>=1.0->checklist==0.0.11->allennlp) (0.8.4)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter>=1.0->checklist==0.0.11->allennlp) (0.7.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter>=1.0->checklist==0.0.11->allennlp) (0.5.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from patternfork-nosql->checklist==0.0.11->allennlp) (0.16.0)\n",
            "Collecting backports.csv\n",
            "  Downloading backports.csv-1.0.7-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from patternfork-nosql->checklist==0.0.11->allennlp) (4.6.3)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from patternfork-nosql->checklist==0.0.11->allennlp) (4.2.6)\n",
            "Collecting feedparser\n",
            "  Downloading feedparser-6.0.8-py3-none-any.whl (81 kB)\n",
            "\u001b[K     |████████████████████████████████| 81 kB 9.7 MB/s \n",
            "\u001b[?25hCollecting pdfminer.six\n",
            "  Downloading pdfminer.six-20211012-py3-none-any.whl (5.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6 MB 41.5 MB/s \n",
            "\u001b[?25hCollecting python-docx\n",
            "  Downloading python-docx-0.8.11.tar.gz (5.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6 MB 30.0 MB/s \n",
            "\u001b[?25hCollecting cherrypy\n",
            "  Downloading CherryPy-18.6.1-py2.py3-none-any.whl (419 kB)\n",
            "\u001b[K     |████████████████████████████████| 419 kB 31.2 MB/s \n",
            "\u001b[?25hCollecting zc.lockfile\n",
            "  Downloading zc.lockfile-2.0-py2.py3-none-any.whl (9.7 kB)\n",
            "Collecting portend>=2.1.1\n",
            "  Downloading portend-3.1.0-py3-none-any.whl (5.3 kB)\n",
            "Collecting cheroot>=8.2.1\n",
            "  Downloading cheroot-8.6.0-py2.py3-none-any.whl (104 kB)\n",
            "\u001b[K     |████████████████████████████████| 104 kB 53.7 MB/s \n",
            "\u001b[?25hCollecting jaraco.collections\n",
            "  Downloading jaraco.collections-3.5.1-py3-none-any.whl (10 kB)\n",
            "Collecting jaraco.functools\n",
            "  Downloading jaraco.functools-3.5.0-py3-none-any.whl (7.0 kB)\n",
            "Collecting tempora>=1.8\n",
            "  Downloading tempora-5.0.1-py3-none-any.whl (15 kB)\n",
            "Collecting sgmllib3k\n",
            "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
            "Collecting jaraco.classes\n",
            "  Downloading jaraco.classes-3.2.1-py3-none-any.whl (5.6 kB)\n",
            "Collecting jaraco.text\n",
            "  Downloading jaraco.text-3.7.0-py3-none-any.whl (8.6 kB)\n",
            "Collecting jaraco.context>=4.1\n",
            "  Downloading jaraco.context-4.1.1-py3-none-any.whl (4.4 kB)\n",
            "Collecting cryptography\n",
            "  Downloading cryptography-36.0.1-cp36-abi3-manylinux_2_24_x86_64.whl (3.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.6 MB 39.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography->pdfminer.six->patternfork-nosql->checklist==0.0.11->allennlp) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography->pdfminer.six->patternfork-nosql->checklist==0.0.11->allennlp) (2.21)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp) (1.11.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp) (1.4.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->allennlp) (0.7.1)\n",
            "Requirement already satisfied: qtpy in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter>=1.0->checklist==0.0.11->allennlp) (2.0.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<4.16,>=4.1->allennlp) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->allennlp) (3.1.0)\n",
            "Building wheels for collected packages: checklist, fairscale, jsonnet, iso-639, pathtools, patternfork-nosql, python-docx, sgmllib3k\n",
            "  Building wheel for checklist (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for checklist: filename=checklist-0.0.11-py3-none-any.whl size=12165635 sha256=c6367a03345f21c1e873f2a21d47543fcd88f6a928439bf2a09df0a643ef0cc5\n",
            "  Stored in directory: /root/.cache/pip/wheels/6a/8a/07/6446879be434879c27671c83443727d74cecf6b630c8a24d03\n",
            "  Building wheel for fairscale (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fairscale: filename=fairscale-0.4.5-py3-none-any.whl size=297992 sha256=edf071947dfd335bccd7f26e228bd7406a87170f37168b6b45df3ff8a2abb1d2\n",
            "  Stored in directory: /root/.cache/pip/wheels/83/d0/90/bcfc419ab267ea41fda54216f0c99e3faf9bab9b38ec760c46\n",
            "  Building wheel for jsonnet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jsonnet: filename=jsonnet-0.18.0-cp37-cp37m-linux_x86_64.whl size=3994566 sha256=ac032ee6dea72ba7eaebc62a3ac9a3fea8d4200be745c844233dd4b5cfa065d8\n",
            "  Stored in directory: /root/.cache/pip/wheels/a9/63/f9/a653f9c21575e6ff271ee6a49939aa002005174cea6c35919d\n",
            "  Building wheel for iso-639 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for iso-639: filename=iso_639-0.4.5-py3-none-any.whl size=169061 sha256=795d58fd2a1c62b7c2d9162a0686028a8938ef570f6b6dcb3a8daa4a9e6e2291\n",
            "  Stored in directory: /root/.cache/pip/wheels/47/60/19/6d020fc92138ed1b113a18271e83ea4b5525fe770cb45b9a2e\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=9a0ca44a28ed0a19fb62fd49810eeedec4a21c9db7f816c817ca9a8f61017005\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n",
            "  Building wheel for patternfork-nosql (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for patternfork-nosql: filename=patternfork_nosql-3.6-py3-none-any.whl size=22332804 sha256=e9ede7bb59c5a98015bf06765e1b0289cec72d00b75a30479a3c2efb73fab36a\n",
            "  Stored in directory: /root/.cache/pip/wheels/97/72/8f/5305fe28168f93b658da9ed433b9a1d3ec90594faa0c9aaf4b\n",
            "  Building wheel for python-docx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-docx: filename=python_docx-0.8.11-py3-none-any.whl size=184507 sha256=81871178442c004bdb42f4bd791860bdb16be8b5c6df3b30127f87c9f813eff9\n",
            "  Stored in directory: /root/.cache/pip/wheels/f6/6f/b9/d798122a8b55b74ad30b5f52b01482169b445fbb84a11797a6\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6066 sha256=54455209c97543566844848d2f03ebf9bc3b9b36e10e7ee5728f0b9365bf26bd\n",
            "  Stored in directory: /root/.cache/pip/wheels/73/ad/a4/0dff4a6ef231fc0dfa12ffbac2a36cebfdddfe059f50e019aa\n",
            "Successfully built checklist fairscale jsonnet iso-639 pathtools patternfork-nosql python-docx sgmllib3k\n",
            "Installing collected packages: urllib3, jaraco.functools, jaraco.context, tempora, jmespath, jaraco.text, jaraco.classes, zc.lockfile, smmap, sgmllib3k, pyyaml, portend, jaraco.collections, cryptography, cheroot, botocore, tokenizers, sacremoses, s3transfer, python-docx, pdfminer.six, huggingface-hub, gitdb, feedparser, cherrypy, backports.csv, yaspin, transformers, shortuuid, sentry-sdk, patternfork-nosql, pathtools, munch, iso-639, GitPython, docker-pycreds, boto3, wandb, tensorboardX, sentencepiece, jsonnet, fairscale, checklist, cached-path, base58, allennlp\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed GitPython-3.1.26 allennlp-2.9.0 backports.csv-1.0.7 base58-2.1.1 boto3-1.20.52 botocore-1.23.52 cached-path-1.0.2 checklist-0.0.11 cheroot-8.6.0 cherrypy-18.6.1 cryptography-36.0.1 docker-pycreds-0.4.0 fairscale-0.4.5 feedparser-6.0.8 gitdb-4.0.9 huggingface-hub-0.2.1 iso-639-0.4.5 jaraco.classes-3.2.1 jaraco.collections-3.5.1 jaraco.context-4.1.1 jaraco.functools-3.5.0 jaraco.text-3.7.0 jmespath-0.10.0 jsonnet-0.18.0 munch-2.5.0 pathtools-0.1.2 patternfork-nosql-3.6 pdfminer.six-20211012 portend-3.1.0 python-docx-0.8.11 pyyaml-6.0 s3transfer-0.5.1 sacremoses-0.0.47 sentencepiece-0.1.96 sentry-sdk-1.5.4 sgmllib3k-1.0.0 shortuuid-1.0.8 smmap-5.0.0 tempora-5.0.1 tensorboardX-2.4.1 tokenizers-0.10.3 transformers-4.15.0 urllib3-1.25.11 wandb-0.12.10 yaspin-2.1.0 zc.lockfile-2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade google-cloud-storage"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RaQWFzsQoR4i",
        "outputId": "412854c4-efea-4d85-a2aa-d6560f5196cd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.7/dist-packages (1.18.1)\n",
            "Collecting google-cloud-storage\n",
            "  Downloading google_cloud_storage-2.1.0-py2.py3-none-any.whl (106 kB)\n",
            "\u001b[K     |████████████████████████████████| 106 kB 11.0 MB/s \n",
            "\u001b[?25hCollecting google-cloud-core<3.0dev,>=1.6.0\n",
            "  Downloading google_cloud_core-2.2.2-py2.py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage) (2.23.0)\n",
            "Collecting google-api-core<3.0dev,>=1.29.0\n",
            "  Downloading google_api_core-2.5.0-py2.py3-none-any.whl (111 kB)\n",
            "\u001b[K     |████████████████████████████████| 111 kB 25.2 MB/s \n",
            "\u001b[?25hCollecting google-resumable-media>=1.3.0\n",
            "  Downloading google_resumable_media-2.2.1-py2.py3-none-any.whl (75 kB)\n",
            "\u001b[K     |████████████████████████████████| 75 kB 4.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage) (3.17.3)\n",
            "Requirement already satisfied: google-auth<3.0dev,>=1.25.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage) (1.35.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.52.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0dev,>=1.29.0->google-cloud-storage) (1.54.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (4.2.4)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (57.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (0.2.8)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (1.15.0)\n",
            "Collecting google-crc32c<2.0dev,>=1.0\n",
            "  Downloading google_crc32c-1.3.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (38 kB)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=1.25.0->google-cloud-storage) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (1.25.11)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2021.10.8)\n",
            "Installing collected packages: google-crc32c, google-api-core, google-resumable-media, google-cloud-core, google-cloud-storage\n",
            "  Attempting uninstall: google-api-core\n",
            "    Found existing installation: google-api-core 1.26.3\n",
            "    Uninstalling google-api-core-1.26.3:\n",
            "      Successfully uninstalled google-api-core-1.26.3\n",
            "  Attempting uninstall: google-resumable-media\n",
            "    Found existing installation: google-resumable-media 0.4.1\n",
            "    Uninstalling google-resumable-media-0.4.1:\n",
            "      Successfully uninstalled google-resumable-media-0.4.1\n",
            "  Attempting uninstall: google-cloud-core\n",
            "    Found existing installation: google-cloud-core 1.0.3\n",
            "    Uninstalling google-cloud-core-1.0.3:\n",
            "      Successfully uninstalled google-cloud-core-1.0.3\n",
            "  Attempting uninstall: google-cloud-storage\n",
            "    Found existing installation: google-cloud-storage 1.18.1\n",
            "    Uninstalling google-cloud-storage-1.18.1:\n",
            "      Successfully uninstalled google-cloud-storage-1.18.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-cloud-translate 1.5.0 requires google-api-core[grpc]<2.0.0dev,>=1.6.0, but you have google-api-core 2.5.0 which is incompatible.\n",
            "google-cloud-translate 1.5.0 requires google-cloud-core<2.0dev,>=1.0.0, but you have google-cloud-core 2.2.2 which is incompatible.\n",
            "google-cloud-language 1.2.0 requires google-api-core[grpc]<2.0.0dev,>=1.6.0, but you have google-api-core 2.5.0 which is incompatible.\n",
            "google-cloud-firestore 1.7.0 requires google-api-core[grpc]<2.0.0dev,>=1.14.0, but you have google-api-core 2.5.0 which is incompatible.\n",
            "google-cloud-firestore 1.7.0 requires google-cloud-core<2.0dev,>=1.0.3, but you have google-cloud-core 2.2.2 which is incompatible.\n",
            "google-cloud-datastore 1.8.0 requires google-api-core[grpc]<2.0.0dev,>=1.6.0, but you have google-api-core 2.5.0 which is incompatible.\n",
            "google-cloud-datastore 1.8.0 requires google-cloud-core<2.0dev,>=1.0.0, but you have google-cloud-core 2.2.2 which is incompatible.\n",
            "google-cloud-bigquery 1.21.0 requires google-cloud-core<2.0dev,>=1.0.3, but you have google-cloud-core 2.2.2 which is incompatible.\n",
            "google-cloud-bigquery 1.21.0 requires google-resumable-media!=0.4.0,<0.5.0dev,>=0.3.1, but you have google-resumable-media 2.2.1 which is incompatible.\n",
            "google-cloud-bigquery-storage 1.1.0 requires google-api-core[grpc]<2.0.0dev,>=1.14.0, but you have google-api-core 2.5.0 which is incompatible.\n",
            "firebase-admin 4.4.0 requires google-api-core[grpc]<2.0.0dev,>=1.14.0; platform_python_implementation != \"PyPy\", but you have google-api-core 2.5.0 which is incompatible.\n",
            "cached-path 1.0.2 requires google-cloud-storage<2.0,>=1.0, but you have google-cloud-storage 2.1.0 which is incompatible.\u001b[0m\n",
            "Successfully installed google-api-core-2.5.0 google-cloud-core-2.2.2 google-cloud-storage-2.1.0 google-crc32c-1.3.0 google-resumable-media-2.2.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd drive/MyDrive/DescribingTextureCopy/DescribingTextures/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGchzGCZpNc-",
        "outputId": "13cae29e-c789-4828-f8c5-f84fad8eb229"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/DescribingTextureCopy/DescribingTextures\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "zH5zZyT6MaPs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python models/triplet_match/train.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDQKA_CtpX5P",
        "outputId": "a8856c99-a335-493b-cc54-d3e53541a55a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DEVICE: cuda\n",
            "EVAL_SPLIT: train\n",
            "INIT_WORD_EMBED: fast_text\n",
            "LANG_INPUT: phrase\n",
            "LOAD_WEIGHTS: ../../DomainToText_AMLProject/outputs/triplet_match/BEST_checkpoint.pth\n",
            "LOSS:\n",
            "  IMG_SENT_WEIGHTS:\n",
            "  - 1.0\n",
            "  - 1.0\n",
            "  MARGIN: 1.0\n",
            "MODEL:\n",
            "  DISTANCE: l2_s\n",
            "  IMG_FEATS:\n",
            "  - 2\n",
            "  - 4\n",
            "  LANG_ENCODER: bert\n",
            "  VEC_DIM: 256\n",
            "OUTPUT_PATH: output/triplet_match/temp\n",
            "RAND_SEED: 2020\n",
            "TRAIN:\n",
            "  ADAM:\n",
            "    ALPHA: 0.8\n",
            "    BETA: 0.999\n",
            "    EPSILON: 1.0e-08\n",
            "  BATCH_SIZE: 16\n",
            "  CHECKPOINT_EVERY_EPOCH: 0.5\n",
            "  EARLY_STOP_EVAL_COUNT: 40\n",
            "  EVAL_EVERY_EPOCH: 0.05\n",
            "  INIT_LR: 0.0001\n",
            "  LR_DECAY_EVAL_COUNT: 10\n",
            "  LR_DECAY_GAMMA: 0.1\n",
            "  MAX_EPOCH: 6\n",
            "  TUNE_LANG_ENCODER: false\n",
            "  TUNE_RESNET: true\n",
            "  WEIGHT_DECAY: 1.0e-06\n",
            "TRAIN_SPLIT: train\n",
            "\n",
            "TextureDescriptionData ready. \n",
            "655 phrases with frequency above 10.\n",
            "Image count: train 432, val 0, test 0\n",
            "Downloading: \"https://download.pytorch.org/models/resnet101-63fe2227.pth\" to /root/.cache/torch/hub/checkpoints/resnet101-63fe2227.pth\n",
            "100% 171M/171M [00:01<00:00, 162MB/s]\n",
            "Downloading: 100% 226k/226k [00:00<00:00, 942kB/s] \n",
            "Downloading: 100% 28.0/28.0 [00:00<00:00, 24.0kB/s]\n",
            "Downloading: 100% 455k/455k [00:00<00:00, 1.41MB/s]\n",
            "Downloading: 100% 570/570 [00:00<00:00, 458kB/s]\n",
            "Downloading: 100% 420M/420M [00:10<00:00, 42.4MB/s]\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "STAT pos_dist: shape torch.Size([16]) device cuda:0; mean 12.456; min 10.131; max 16.831; std 1.747\n",
            "STAT neg_img_dist: shape torch.Size([16]) device cuda:0; mean 14.021; min 11.413; max 18.815; std 1.994\n",
            "STAT neg_sent_dist: shape torch.Size([16]) device cuda:0; mean 12.363; min 10.246; max 14.640; std 1.281\n",
            "[02/10 15:59:53] epoch-1 step-1: loss 0.8156 (neg_img: 0.4528, neg_lang: 1.1784); lr 1.0E-04\n",
            "STAT pos_dist: shape torch.Size([16]) device cuda:0; mean 13.950; min 9.201; max 19.476; std 3.223\n",
            "STAT neg_img_dist: shape torch.Size([16]) device cuda:0; mean 14.925; min 10.388; max 19.076; std 2.198\n",
            "STAT neg_sent_dist: shape torch.Size([16]) device cuda:0; mean 18.160; min 14.486; max 27.463; std 3.304\n",
            "[02/10 16:00:19] epoch-1 step-2: loss 0.7451 (neg_img: 1.0901, neg_lang: 0.4001); lr 1.0E-04\n",
            "STAT pos_dist: shape torch.Size([16]) device cuda:0; mean 18.921; min 14.604; max 27.280; std 3.660\n",
            "STAT neg_img_dist: shape torch.Size([16]) device cuda:0; mean 20.411; min 16.140; max 28.220; std 3.002\n",
            "STAT neg_sent_dist: shape torch.Size([16]) device cuda:0; mean 22.120; min 10.792; max 28.999; std 4.643\n",
            "[02/10 16:00:36] epoch-1 step-3: loss 0.7734 (neg_img: 1.0566, neg_lang: 0.4903); lr 1.0E-04\n",
            "STAT pos_dist: shape torch.Size([16]) device cuda:0; mean 19.828; min 15.092; max 26.642; std 3.519\n",
            "STAT neg_img_dist: shape torch.Size([16]) device cuda:0; mean 19.693; min 14.367; max 30.495; std 4.237\n",
            "STAT neg_sent_dist: shape torch.Size([16]) device cuda:0; mean 24.851; min 18.706; max 32.088; std 3.731\n",
            "[02/10 16:00:48] epoch-1 step-4: loss 1.1043 (neg_img: 2.0277, neg_lang: 0.1809); lr 1.0E-04\n",
            "STAT pos_dist: shape torch.Size([16]) device cuda:0; mean 21.678; min 15.153; max 30.305; std 4.489\n",
            "STAT neg_img_dist: shape torch.Size([16]) device cuda:0; mean 23.118; min 14.454; max 40.986; std 7.532\n",
            "STAT neg_sent_dist: shape torch.Size([16]) device cuda:0; mean 27.602; min 18.667; max 37.244; std 4.959\n",
            "[02/10 16:00:59] epoch-1 step-5: loss 1.1843 (neg_img: 2.0484, neg_lang: 0.3202); lr 1.0E-04\n",
            "STAT pred_scores: shape torch.Size([432, 655]) device cpu; mean -21.352; min -84.125; max -7.544; std 5.331\n",
            "/content/drive/MyDrive/DescribingTextureCopy/DescribingTextures/data_api/utils/retrieval_metrics.py:127: RuntimeWarning: invalid value encountered in true_divide\n",
            "  recall = np.nan_to_num(pred_num * 1.0 / gt_count)\n",
            "## retrieve_eval phrase2img on train ##\n",
            "mean_average_precision: 0.0051\n",
            "mean_reciprocal_rank: 0.0098\n",
            "precision_at_005: 0.0049\n",
            "precision_at_010: 0.0053\n",
            "precision_at_020: 0.0043\n",
            "precision_at_050: 0.0034\n",
            "precision_at_100: 0.0032\n",
            "r_precision: 0.0023\n",
            "recall_at_005: 0.0016\n",
            "recall_at_010: 0.0039\n",
            "recall_at_020: 0.0061\n",
            "recall_at_050: 0.0088\n",
            "recall_at_100: 0.0135\n",
            "## retrieve_eval img2phrase on train ##\n",
            "mean_average_precision: 0.3843\n",
            "mean_reciprocal_rank: 0.4750\n",
            "precision_at_005: 0.1713\n",
            "precision_at_010: 0.1025\n",
            "precision_at_020: 0.0608\n",
            "precision_at_050: 0.0262\n",
            "precision_at_100: 0.0135\n",
            "r_precision: 0.0021\n",
            "recall_at_005: 0.4730\n",
            "recall_at_010: 0.5934\n",
            "recall_at_020: 0.7569\n",
            "recall_at_050: 0.8202\n",
            "recall_at_100: 0.8407\n",
            "EVAL: new best!\n",
            "STAT pred_scores: shape torch.Size([432, 655]) device cpu; mean -22.799; min -58.437; max -9.239; std 5.581\n",
            "## retrieve_eval phrase2img on train ##\n",
            "mean_average_precision: 0.0043\n",
            "mean_reciprocal_rank: 0.0077\n",
            "precision_at_005: 0.0040\n",
            "precision_at_010: 0.0035\n",
            "precision_at_020: 0.0037\n",
            "precision_at_050: 0.0034\n",
            "precision_at_100: 0.0035\n",
            "r_precision: 0.0023\n",
            "recall_at_005: 0.0016\n",
            "recall_at_010: 0.0018\n",
            "recall_at_020: 0.0040\n",
            "recall_at_050: 0.0139\n",
            "recall_at_100: 0.0208\n",
            "## retrieve_eval img2phrase on train ##\n",
            "mean_average_precision: 0.1537\n",
            "mean_reciprocal_rank: 0.2073\n",
            "precision_at_005: 0.0657\n",
            "precision_at_010: 0.0507\n",
            "precision_at_020: 0.0352\n",
            "precision_at_050: 0.0223\n",
            "precision_at_100: 0.0127\n",
            "r_precision: 0.0021\n",
            "recall_at_005: 0.1825\n",
            "recall_at_010: 0.2728\n",
            "recall_at_020: 0.3885\n",
            "recall_at_050: 0.7025\n",
            "recall_at_100: 0.8032\n",
            "EVAL: since last best: 1\n",
            "STAT pred_scores: shape torch.Size([432, 655]) device cpu; mean -26.790; min -94.135; max -10.729; std 6.626\n",
            "## retrieve_eval phrase2img on train ##\n",
            "mean_average_precision: 0.0036\n",
            "mean_reciprocal_rank: 0.0068\n",
            "precision_at_005: 0.0046\n",
            "precision_at_010: 0.0041\n",
            "precision_at_020: 0.0040\n",
            "precision_at_050: 0.0035\n",
            "precision_at_100: 0.0028\n",
            "r_precision: 0.0023\n",
            "recall_at_005: 0.0008\n",
            "recall_at_010: 0.0010\n",
            "recall_at_020: 0.0017\n",
            "recall_at_050: 0.0035\n",
            "recall_at_100: 0.0075\n",
            "## retrieve_eval img2phrase on train ##\n",
            "mean_average_precision: 0.1427\n",
            "mean_reciprocal_rank: 0.1642\n",
            "precision_at_005: 0.0792\n",
            "precision_at_010: 0.0743\n",
            "precision_at_020: 0.0522\n",
            "precision_at_050: 0.0243\n",
            "precision_at_100: 0.0124\n",
            "r_precision: 0.0021\n",
            "recall_at_005: 0.2091\n",
            "recall_at_010: 0.4186\n",
            "recall_at_020: 0.6705\n",
            "recall_at_050: 0.7793\n",
            "recall_at_100: 0.7924\n",
            "EVAL: since last best: 2\n",
            "STAT pred_scores: shape torch.Size([432, 655]) device cpu; mean -31.663; min -49.438; max -8.246; std 5.584\n",
            "## retrieve_eval phrase2img on train ##\n",
            "mean_average_precision: 0.0034\n",
            "mean_reciprocal_rank: 0.0045\n",
            "precision_at_005: 0.0034\n",
            "precision_at_010: 0.0031\n",
            "precision_at_020: 0.0027\n",
            "precision_at_050: 0.0029\n",
            "precision_at_100: 0.0030\n",
            "r_precision: 0.0023\n",
            "recall_at_005: 0.0003\n",
            "recall_at_010: 0.0010\n",
            "recall_at_020: 0.0013\n",
            "recall_at_050: 0.0048\n",
            "recall_at_100: 0.0132\n",
            "## retrieve_eval img2phrase on train ##\n",
            "mean_average_precision: 0.1107\n",
            "mean_reciprocal_rank: 0.1061\n",
            "precision_at_005: 0.0116\n",
            "precision_at_010: 0.0877\n",
            "precision_at_020: 0.0631\n",
            "precision_at_050: 0.0266\n",
            "precision_at_100: 0.0135\n",
            "r_precision: 0.0021\n",
            "recall_at_005: 0.0309\n",
            "recall_at_010: 0.5413\n",
            "recall_at_020: 0.8005\n",
            "recall_at_050: 0.8314\n",
            "recall_at_100: 0.8407\n",
            "EVAL: since last best: 3\n",
            "STAT pos_dist: shape torch.Size([16]) device cuda:0; mean 12.018; min 7.893; max 18.036; std 3.061\n",
            "STAT neg_img_dist: shape torch.Size([16]) device cuda:0; mean 14.488; min 9.755; max 22.313; std 3.422\n",
            "STAT neg_sent_dist: shape torch.Size([16]) device cuda:0; mean 28.548; min 11.040; max 35.643; std 7.446\n",
            "[02/10 16:08:06] epoch-1 step-50: loss 0.0304 (neg_img: 0.0367, neg_lang: 0.0242); lr 1.0E-04\n",
            "STAT pred_scores: shape torch.Size([432, 655]) device cpu; mean -25.701; min -50.731; max -10.232; std 5.131\n",
            "## retrieve_eval phrase2img on train ##\n",
            "mean_average_precision: 0.0036\n",
            "mean_reciprocal_rank: 0.0031\n",
            "precision_at_005: 0.0024\n",
            "precision_at_010: 0.0032\n",
            "precision_at_020: 0.0038\n",
            "precision_at_050: 0.0034\n",
            "precision_at_100: 0.0034\n",
            "r_precision: 0.0023\n",
            "recall_at_005: 0.0001\n",
            "recall_at_010: 0.0027\n",
            "recall_at_020: 0.0035\n",
            "recall_at_050: 0.0065\n",
            "recall_at_100: 0.0128\n",
            "## retrieve_eval img2phrase on train ##\n",
            "mean_average_precision: 0.1756\n",
            "mean_reciprocal_rank: 0.1818\n",
            "precision_at_005: 0.0954\n",
            "precision_at_010: 0.1211\n",
            "precision_at_020: 0.0642\n",
            "precision_at_050: 0.0260\n",
            "precision_at_100: 0.0132\n",
            "r_precision: 0.0021\n",
            "recall_at_005: 0.2932\n",
            "recall_at_010: 0.7755\n",
            "recall_at_020: 0.8094\n",
            "recall_at_050: 0.8167\n",
            "recall_at_100: 0.8256\n",
            "EVAL: since last best: 4\n",
            "STAT pred_scores: shape torch.Size([432, 655]) device cpu; mean -18.711; min -93.147; max -9.057; std 4.223\n",
            "## retrieve_eval phrase2img on train ##\n",
            "mean_average_precision: 0.0045\n",
            "mean_reciprocal_rank: 0.0050\n",
            "precision_at_005: 0.0046\n",
            "precision_at_010: 0.0050\n",
            "precision_at_020: 0.0048\n",
            "precision_at_050: 0.0043\n",
            "precision_at_100: 0.0041\n",
            "r_precision: 0.0023\n",
            "recall_at_005: 0.0005\n",
            "recall_at_010: 0.0012\n",
            "recall_at_020: 0.0031\n",
            "recall_at_050: 0.0075\n",
            "recall_at_100: 0.0132\n",
            "## retrieve_eval img2phrase on train ##\n",
            "mean_average_precision: 0.2311\n",
            "mean_reciprocal_rank: 0.2954\n",
            "precision_at_005: 0.1481\n",
            "precision_at_010: 0.0794\n",
            "precision_at_020: 0.0575\n",
            "precision_at_050: 0.0248\n",
            "precision_at_100: 0.0126\n",
            "r_precision: 0.0021\n",
            "recall_at_005: 0.4201\n",
            "recall_at_010: 0.4529\n",
            "recall_at_020: 0.7454\n",
            "recall_at_050: 0.7913\n",
            "recall_at_100: 0.7986\n",
            "EVAL: since last best: 5\n",
            "STAT pred_scores: shape torch.Size([432, 655]) device cpu; mean -21.812; min -143.374; max -9.446; std 6.208\n",
            "## retrieve_eval phrase2img on train ##\n",
            "mean_average_precision: 0.0041\n",
            "mean_reciprocal_rank: 0.0061\n",
            "precision_at_005: 0.0049\n",
            "precision_at_010: 0.0040\n",
            "precision_at_020: 0.0040\n",
            "precision_at_050: 0.0038\n",
            "precision_at_100: 0.0038\n",
            "r_precision: 0.0023\n",
            "recall_at_005: 0.0005\n",
            "recall_at_010: 0.0006\n",
            "recall_at_020: 0.0027\n",
            "recall_at_050: 0.0066\n",
            "recall_at_100: 0.0162\n",
            "## retrieve_eval img2phrase on train ##\n",
            "mean_average_precision: 0.4443\n",
            "mean_reciprocal_rank: 0.5282\n",
            "precision_at_005: 0.1472\n",
            "precision_at_010: 0.1190\n",
            "precision_at_020: 0.0631\n",
            "precision_at_050: 0.0253\n",
            "precision_at_100: 0.0127\n",
            "r_precision: 0.0021\n",
            "recall_at_005: 0.5096\n",
            "recall_at_010: 0.7589\n",
            "recall_at_020: 0.8005\n",
            "recall_at_050: 0.8021\n",
            "recall_at_100: 0.8040\n",
            "EVAL: new best!\n",
            "STAT pred_scores: shape torch.Size([432, 655]) device cpu; mean -19.123; min -44.375; max -9.263; std 3.185\n",
            "## retrieve_eval phrase2img on train ##\n",
            "mean_average_precision: 0.0044\n",
            "mean_reciprocal_rank: 0.0069\n",
            "precision_at_005: 0.0046\n",
            "precision_at_010: 0.0043\n",
            "precision_at_020: 0.0044\n",
            "precision_at_050: 0.0042\n",
            "precision_at_100: 0.0039\n",
            "r_precision: 0.0023\n",
            "recall_at_005: 0.0004\n",
            "recall_at_010: 0.0007\n",
            "recall_at_020: 0.0026\n",
            "recall_at_050: 0.0098\n",
            "recall_at_100: 0.0128\n",
            "## retrieve_eval img2phrase on train ##\n",
            "mean_average_precision: 0.3306\n",
            "mean_reciprocal_rank: 0.4898\n",
            "precision_at_005: 0.1042\n",
            "precision_at_010: 0.0669\n",
            "precision_at_020: 0.0575\n",
            "precision_at_050: 0.0253\n",
            "precision_at_100: 0.0131\n",
            "r_precision: 0.0021\n",
            "recall_at_005: 0.3152\n",
            "recall_at_010: 0.3970\n",
            "recall_at_020: 0.7461\n",
            "recall_at_050: 0.8052\n",
            "recall_at_100: 0.8233\n",
            "EVAL: since last best: 1\n",
            "STAT pos_dist: shape torch.Size([16]) device cuda:0; mean 10.772; min 7.591; max 13.199; std 1.630\n",
            "STAT neg_img_dist: shape torch.Size([16]) device cuda:0; mean 14.302; min 10.669; max 17.701; std 2.219\n",
            "STAT neg_sent_dist: shape torch.Size([16]) device cuda:0; mean 20.779; min 13.448; max 29.074; std 3.694\n",
            "[02/10 16:13:10] epoch-1 step-100: loss 0.0000 (neg_img: 0.0000, neg_lang: 0.0000); lr 1.0E-04\n",
            "STAT pred_scores: shape torch.Size([432, 655]) device cpu; mean -20.924; min -44.420; max -6.518; std 4.325\n",
            "## retrieve_eval phrase2img on train ##\n",
            "mean_average_precision: 0.0044\n",
            "mean_reciprocal_rank: 0.0063\n",
            "precision_at_005: 0.0046\n",
            "precision_at_010: 0.0044\n",
            "precision_at_020: 0.0045\n",
            "precision_at_050: 0.0043\n",
            "precision_at_100: 0.0038\n",
            "r_precision: 0.0023\n",
            "recall_at_005: 0.0004\n",
            "recall_at_010: 0.0006\n",
            "recall_at_020: 0.0023\n",
            "recall_at_050: 0.0073\n",
            "recall_at_100: 0.0135\n",
            "## retrieve_eval img2phrase on train ##\n",
            "mean_average_precision: 0.0652\n",
            "mean_reciprocal_rank: 0.0666\n",
            "precision_at_005: 0.0009\n",
            "precision_at_010: 0.0312\n",
            "precision_at_020: 0.0341\n",
            "precision_at_050: 0.0255\n",
            "precision_at_100: 0.0135\n",
            "r_precision: 0.0021\n",
            "recall_at_005: 0.0035\n",
            "recall_at_010: 0.2735\n",
            "recall_at_020: 0.4904\n",
            "recall_at_050: 0.8086\n",
            "recall_at_100: 0.8418\n",
            "EVAL: since last best: 2\n",
            "STAT pred_scores: shape torch.Size([432, 655]) device cpu; mean -20.720; min -33.436; max -6.057; std 3.368\n",
            "## retrieve_eval phrase2img on train ##\n",
            "mean_average_precision: 0.0045\n",
            "mean_reciprocal_rank: 0.0063\n",
            "precision_at_005: 0.0037\n",
            "precision_at_010: 0.0040\n",
            "precision_at_020: 0.0040\n",
            "precision_at_050: 0.0040\n",
            "precision_at_100: 0.0036\n",
            "r_precision: 0.0023\n",
            "recall_at_005: 0.0004\n",
            "recall_at_010: 0.0035\n",
            "recall_at_020: 0.0038\n",
            "recall_at_050: 0.0078\n",
            "recall_at_100: 0.0103\n",
            "## retrieve_eval img2phrase on train ##\n",
            "mean_average_precision: 0.1853\n",
            "mean_reciprocal_rank: 0.2120\n",
            "precision_at_005: 0.0833\n",
            "precision_at_010: 0.0456\n",
            "precision_at_020: 0.0400\n",
            "precision_at_050: 0.0267\n",
            "precision_at_100: 0.0138\n",
            "r_precision: 0.0021\n",
            "recall_at_005: 0.3264\n",
            "recall_at_010: 0.3468\n",
            "recall_at_020: 0.5521\n",
            "recall_at_050: 0.8329\n",
            "recall_at_100: 0.8542\n",
            "EVAL: since last best: 3\n",
            "STAT pred_scores: shape torch.Size([432, 655]) device cpu; mean -25.965; min -41.279; max -8.500; std 3.635\n",
            "## retrieve_eval phrase2img on train ##\n",
            "mean_average_precision: 0.0042\n",
            "mean_reciprocal_rank: 0.0065\n",
            "precision_at_005: 0.0037\n",
            "precision_at_010: 0.0034\n",
            "precision_at_020: 0.0034\n",
            "precision_at_050: 0.0033\n",
            "precision_at_100: 0.0033\n",
            "r_precision: 0.0023\n",
            "recall_at_005: 0.0019\n",
            "recall_at_010: 0.0035\n",
            "recall_at_020: 0.0042\n",
            "recall_at_050: 0.0054\n",
            "recall_at_100: 0.0101\n",
            "## retrieve_eval img2phrase on train ##\n",
            "mean_average_precision: 0.4938\n",
            "mean_reciprocal_rank: 0.5537\n",
            "precision_at_005: 0.1847\n",
            "precision_at_010: 0.0972\n",
            "precision_at_020: 0.0646\n",
            "precision_at_050: 0.0271\n",
            "precision_at_100: 0.0137\n",
            "r_precision: 0.0021\n",
            "recall_at_005: 0.6235\n",
            "recall_at_010: 0.6481\n",
            "recall_at_020: 0.8148\n",
            "recall_at_050: 0.8410\n",
            "recall_at_100: 0.8492\n",
            "EVAL: new best!\n",
            "STAT pred_scores: shape torch.Size([432, 655]) device cpu; mean -21.821; min -37.442; max -8.940; std 3.257\n",
            "## retrieve_eval phrase2img on train ##\n",
            "mean_average_precision: 0.0042\n",
            "mean_reciprocal_rank: 0.0066\n",
            "precision_at_005: 0.0040\n",
            "precision_at_010: 0.0037\n",
            "precision_at_020: 0.0037\n",
            "precision_at_050: 0.0035\n",
            "precision_at_100: 0.0035\n",
            "r_precision: 0.0023\n",
            "recall_at_005: 0.0026\n",
            "recall_at_010: 0.0027\n",
            "recall_at_020: 0.0030\n",
            "recall_at_050: 0.0082\n",
            "recall_at_100: 0.0117\n",
            "## retrieve_eval img2phrase on train ##\n",
            "mean_average_precision: 0.6266\n",
            "mean_reciprocal_rank: 0.7056\n",
            "precision_at_005: 0.2329\n",
            "precision_at_010: 0.1278\n",
            "precision_at_020: 0.0647\n",
            "precision_at_050: 0.0272\n",
            "precision_at_100: 0.0138\n",
            "r_precision: 0.0021\n",
            "recall_at_005: 0.7558\n",
            "recall_at_010: 0.8102\n",
            "recall_at_020: 0.8167\n",
            "recall_at_050: 0.8438\n",
            "recall_at_100: 0.8503\n",
            "EVAL: new best!\n",
            "STAT pos_dist: shape torch.Size([16]) device cuda:0; mean 13.674; min 7.344; max 23.186; std 5.435\n",
            "STAT neg_img_dist: shape torch.Size([16]) device cuda:0; mean 18.019; min 9.226; max 29.689; std 6.603\n",
            "STAT neg_sent_dist: shape torch.Size([16]) device cuda:0; mean 32.907; min 25.164; max 46.190; std 6.115\n",
            "[02/10 16:18:38] epoch-1 step-150: loss 0.0000 (neg_img: 0.0000, neg_lang: 0.0000); lr 1.0E-04\n",
            "STAT pred_scores: shape torch.Size([432, 655]) device cpu; mean -48.460; min -77.711; max -13.569; std 9.420\n",
            "## retrieve_eval phrase2img on train ##\n",
            "mean_average_precision: 0.0043\n",
            "mean_reciprocal_rank: 0.0047\n",
            "precision_at_005: 0.0027\n",
            "precision_at_010: 0.0035\n",
            "precision_at_020: 0.0039\n",
            "precision_at_050: 0.0040\n",
            "precision_at_100: 0.0036\n",
            "r_precision: 0.0023\n",
            "recall_at_005: 0.0018\n",
            "recall_at_010: 0.0022\n",
            "recall_at_020: 0.0035\n",
            "recall_at_050: 0.0076\n",
            "recall_at_100: 0.0146\n",
            "## retrieve_eval img2phrase on train ##\n",
            "mean_average_precision: 0.4695\n",
            "mean_reciprocal_rank: 0.5821\n",
            "precision_at_005: 0.2509\n",
            "precision_at_010: 0.1266\n",
            "precision_at_020: 0.0641\n",
            "precision_at_050: 0.0268\n",
            "precision_at_100: 0.0136\n",
            "r_precision: 0.0021\n",
            "recall_at_005: 0.7975\n",
            "recall_at_010: 0.8036\n",
            "recall_at_020: 0.8106\n",
            "recall_at_050: 0.8333\n",
            "recall_at_100: 0.8441\n",
            "EVAL: since last best: 1\n",
            "STAT pred_scores: shape torch.Size([432, 655]) device cpu; mean -33.741; min -50.267; max -12.221; std 6.182\n",
            "## retrieve_eval phrase2img on train ##\n",
            "mean_average_precision: 0.0041\n",
            "mean_reciprocal_rank: 0.0040\n",
            "precision_at_005: 0.0037\n",
            "precision_at_010: 0.0035\n",
            "precision_at_020: 0.0037\n",
            "precision_at_050: 0.0033\n",
            "precision_at_100: 0.0032\n",
            "r_precision: 0.0023\n",
            "recall_at_005: 0.0024\n",
            "recall_at_010: 0.0027\n",
            "recall_at_020: 0.0047\n",
            "recall_at_050: 0.0058\n",
            "recall_at_100: 0.0106\n",
            "## retrieve_eval img2phrase on train ##\n",
            "mean_average_precision: 0.0789\n",
            "mean_reciprocal_rank: 0.0948\n",
            "precision_at_005: 0.0019\n",
            "precision_at_010: 0.0502\n",
            "precision_at_020: 0.0418\n",
            "precision_at_050: 0.0249\n",
            "precision_at_100: 0.0131\n",
            "r_precision: 0.0021\n",
            "recall_at_005: 0.0042\n",
            "recall_at_010: 0.2998\n",
            "recall_at_020: 0.5818\n",
            "recall_at_050: 0.7951\n",
            "recall_at_100: 0.8237\n",
            "EVAL: since last best: 2\n",
            "STAT pred_scores: shape torch.Size([432, 655]) device cpu; mean -30.724; min -58.803; max -9.938; std 5.327\n",
            "## retrieve_eval phrase2img on train ##\n",
            "mean_average_precision: 0.0031\n",
            "mean_reciprocal_rank: 0.0034\n",
            "precision_at_005: 0.0012\n",
            "precision_at_010: 0.0017\n",
            "precision_at_020: 0.0024\n",
            "precision_at_050: 0.0027\n",
            "precision_at_100: 0.0025\n",
            "r_precision: 0.0023\n",
            "recall_at_005: 0.0003\n",
            "recall_at_010: 0.0003\n",
            "recall_at_020: 0.0030\n",
            "recall_at_050: 0.0080\n",
            "recall_at_100: 0.0184\n",
            "## retrieve_eval img2phrase on train ##\n",
            "mean_average_precision: 0.1551\n",
            "mean_reciprocal_rank: 0.1939\n",
            "precision_at_005: 0.1491\n",
            "precision_at_010: 0.0750\n",
            "precision_at_020: 0.0382\n",
            "precision_at_050: 0.0251\n",
            "precision_at_100: 0.0126\n",
            "r_precision: 0.0021\n",
            "recall_at_005: 0.4977\n",
            "recall_at_010: 0.4992\n",
            "recall_at_020: 0.5085\n",
            "recall_at_050: 0.7967\n",
            "recall_at_100: 0.8002\n",
            "EVAL: since last best: 3\n",
            "STAT pred_scores: shape torch.Size([432, 655]) device cpu; mean -34.749; min -56.595; max -8.160; std 5.764\n",
            "## retrieve_eval phrase2img on train ##\n",
            "mean_average_precision: 0.0033\n",
            "mean_reciprocal_rank: 0.0037\n",
            "precision_at_005: 0.0027\n",
            "precision_at_010: 0.0034\n",
            "precision_at_020: 0.0027\n",
            "precision_at_050: 0.0028\n",
            "precision_at_100: 0.0029\n",
            "r_precision: 0.0023\n",
            "recall_at_005: 0.0004\n",
            "recall_at_010: 0.0008\n",
            "recall_at_020: 0.0012\n",
            "recall_at_050: 0.0061\n",
            "recall_at_100: 0.0169\n",
            "## retrieve_eval img2phrase on train ##\n",
            "mean_average_precision: 0.3249\n",
            "mean_reciprocal_rank: 0.4124\n",
            "precision_at_005: 0.1602\n",
            "precision_at_010: 0.1269\n",
            "precision_at_020: 0.0641\n",
            "precision_at_050: 0.0266\n",
            "precision_at_100: 0.0137\n",
            "r_precision: 0.0021\n",
            "recall_at_005: 0.4560\n",
            "recall_at_010: 0.8032\n",
            "recall_at_020: 0.8086\n",
            "recall_at_050: 0.8283\n",
            "recall_at_100: 0.8457\n",
            "EVAL: since last best: 4\n",
            "STAT pred_scores: shape torch.Size([432, 655]) device cpu; mean -32.515; min -55.054; max -11.707; std 5.468\n",
            "## retrieve_eval phrase2img on train ##\n",
            "mean_average_precision: 0.0041\n",
            "mean_reciprocal_rank: 0.0065\n",
            "precision_at_005: 0.0034\n",
            "precision_at_010: 0.0034\n",
            "precision_at_020: 0.0031\n",
            "precision_at_050: 0.0030\n",
            "precision_at_100: 0.0029\n",
            "r_precision: 0.0023\n",
            "recall_at_005: 0.0009\n",
            "recall_at_010: 0.0026\n",
            "recall_at_020: 0.0048\n",
            "recall_at_050: 0.0100\n",
            "recall_at_100: 0.0168\n",
            "## retrieve_eval img2phrase on train ##\n",
            "mean_average_precision: 0.4214\n",
            "mean_reciprocal_rank: 0.4863\n",
            "precision_at_005: 0.2144\n",
            "precision_at_010: 0.1269\n",
            "precision_at_020: 0.0641\n",
            "precision_at_050: 0.0261\n",
            "precision_at_100: 0.0137\n",
            "r_precision: 0.0021\n",
            "recall_at_005: 0.7060\n",
            "recall_at_010: 0.8032\n",
            "recall_at_020: 0.8086\n",
            "recall_at_050: 0.8183\n",
            "recall_at_100: 0.8445\n",
            "EVAL: since last best: 5\n",
            "STAT pos_dist: shape torch.Size([16]) device cuda:0; mean 13.597; min 6.518; max 19.884; std 3.432\n",
            "STAT neg_img_dist: shape torch.Size([16]) device cuda:0; mean 14.649; min 9.599; max 20.940; std 3.622\n",
            "STAT neg_sent_dist: shape torch.Size([16]) device cuda:0; mean 29.374; min 19.479; max 34.629; std 3.856\n",
            "[02/10 16:24:19] epoch-1 step-200: loss 0.4436 (neg_img: 0.8871, neg_lang: 0.0000); lr 1.0E-04\n",
            "STAT pred_scores: shape torch.Size([432, 655]) device cpu; mean -25.812; min -40.196; max -7.815; std 5.766\n",
            "## retrieve_eval phrase2img on train ##\n",
            "mean_average_precision: 0.0041\n",
            "mean_reciprocal_rank: 0.0050\n",
            "precision_at_005: 0.0031\n",
            "precision_at_010: 0.0031\n",
            "precision_at_020: 0.0032\n",
            "precision_at_050: 0.0035\n",
            "precision_at_100: 0.0034\n",
            "r_precision: 0.0023\n",
            "recall_at_005: 0.0008\n",
            "recall_at_010: 0.0024\n",
            "recall_at_020: 0.0071\n",
            "recall_at_050: 0.0130\n",
            "recall_at_100: 0.0175\n",
            "## retrieve_eval img2phrase on train ##\n",
            "mean_average_precision: 0.2572\n",
            "mean_reciprocal_rank: 0.3948\n",
            "precision_at_005: 0.1213\n",
            "precision_at_010: 0.0725\n",
            "precision_at_020: 0.0397\n",
            "precision_at_050: 0.0172\n",
            "precision_at_100: 0.0092\n",
            "r_precision: 0.0021\n",
            "recall_at_005: 0.4232\n",
            "recall_at_010: 0.4834\n",
            "recall_at_020: 0.5166\n",
            "recall_at_050: 0.5444\n",
            "recall_at_100: 0.5768\n",
            "EVAL: since last best: 6\n",
            "STAT pred_scores: shape torch.Size([432, 655]) device cpu; mean -37.131; min -62.285; max -9.346; std 7.310\n",
            "## retrieve_eval phrase2img on train ##\n",
            "mean_average_precision: 0.0036\n",
            "mean_reciprocal_rank: 0.0036\n",
            "precision_at_005: 0.0031\n",
            "precision_at_010: 0.0029\n",
            "precision_at_020: 0.0033\n",
            "precision_at_050: 0.0034\n",
            "precision_at_100: 0.0033\n",
            "r_precision: 0.0023\n",
            "recall_at_005: 0.0003\n",
            "recall_at_010: 0.0004\n",
            "recall_at_020: 0.0029\n",
            "recall_at_050: 0.0051\n",
            "recall_at_100: 0.0081\n",
            "## retrieve_eval img2phrase on train ##\n",
            "mean_average_precision: 0.5073\n",
            "mean_reciprocal_rank: 0.5465\n",
            "precision_at_005: 0.2528\n",
            "precision_at_010: 0.1324\n",
            "precision_at_020: 0.0674\n",
            "precision_at_050: 0.0275\n",
            "precision_at_100: 0.0138\n",
            "r_precision: 0.0021\n",
            "recall_at_005: 0.8005\n",
            "recall_at_010: 0.8264\n",
            "recall_at_020: 0.8368\n",
            "recall_at_050: 0.8515\n",
            "recall_at_100: 0.8542\n",
            "EVAL: since last best: 7\n",
            "STAT pred_scores: shape torch.Size([432, 655]) device cpu; mean -46.526; min -77.087; max -12.635; std 10.799\n",
            "## retrieve_eval phrase2img on train ##\n",
            "mean_average_precision: 0.0034\n",
            "mean_reciprocal_rank: 0.0027\n",
            "precision_at_005: 0.0018\n",
            "precision_at_010: 0.0024\n",
            "precision_at_020: 0.0025\n",
            "precision_at_050: 0.0030\n",
            "precision_at_100: 0.0030\n",
            "r_precision: 0.0023\n",
            "recall_at_005: 0.0010\n",
            "recall_at_010: 0.0011\n",
            "recall_at_020: 0.0013\n",
            "recall_at_050: 0.0033\n",
            "recall_at_100: 0.0057\n",
            "## retrieve_eval img2phrase on train ##\n",
            "mean_average_precision: 0.3122\n",
            "mean_reciprocal_rank: 0.4191\n",
            "precision_at_005: 0.1505\n",
            "precision_at_010: 0.1227\n",
            "precision_at_020: 0.0613\n",
            "precision_at_050: 0.0261\n",
            "precision_at_100: 0.0132\n",
            "r_precision: 0.0021\n",
            "recall_at_005: 0.5062\n",
            "recall_at_010: 0.7851\n",
            "recall_at_020: 0.7851\n",
            "recall_at_050: 0.8198\n",
            "recall_at_100: 0.8268\n",
            "EVAL: since last best: 8\n",
            "STAT pred_scores: shape torch.Size([432, 655]) device cpu; mean -56.045; min -86.184; max -12.187; std 8.759\n",
            "## retrieve_eval phrase2img on train ##\n",
            "mean_average_precision: 0.0030\n",
            "mean_reciprocal_rank: 0.0025\n",
            "precision_at_005: 0.0018\n",
            "precision_at_010: 0.0024\n",
            "precision_at_020: 0.0030\n",
            "precision_at_050: 0.0032\n",
            "precision_at_100: 0.0032\n",
            "r_precision: 0.0023\n",
            "recall_at_005: 0.0000\n",
            "recall_at_010: 0.0001\n",
            "recall_at_020: 0.0004\n",
            "recall_at_050: 0.0042\n",
            "recall_at_100: 0.0086\n",
            "## retrieve_eval img2phrase on train ##\n",
            "mean_average_precision: 0.2067\n",
            "mean_reciprocal_rank: 0.2816\n",
            "precision_at_005: 0.0995\n",
            "precision_at_010: 0.0563\n",
            "precision_at_020: 0.0653\n",
            "precision_at_050: 0.0262\n",
            "precision_at_100: 0.0133\n",
            "r_precision: 0.0021\n",
            "recall_at_005: 0.2951\n",
            "recall_at_010: 0.3245\n",
            "recall_at_020: 0.8183\n",
            "recall_at_050: 0.8214\n",
            "recall_at_100: 0.8306\n",
            "EVAL: since last best: 9\n",
            "STAT pos_dist: shape torch.Size([16]) device cuda:0; mean 18.192; min 12.766; max 31.836; std 4.903\n",
            "STAT neg_img_dist: shape torch.Size([16]) device cuda:0; mean 20.181; min 14.170; max 34.596; std 4.904\n",
            "STAT neg_sent_dist: shape torch.Size([16]) device cuda:0; mean 47.392; min 29.823; max 56.360; std 7.955\n",
            "[02/10 16:29:22] epoch-2 step-250: loss 0.0628 (neg_img: 0.1255, neg_lang: 0.0000); lr 1.0E-04\n",
            "STAT pred_scores: shape torch.Size([432, 655]) device cpu; mean -28.832; min -76.342; max -8.507; std 5.791\n",
            "## retrieve_eval phrase2img on train ##\n",
            "mean_average_precision: 0.0024\n",
            "mean_reciprocal_rank: 0.0029\n",
            "precision_at_005: 0.0021\n",
            "precision_at_010: 0.0021\n",
            "precision_at_020: 0.0020\n",
            "precision_at_050: 0.0023\n",
            "precision_at_100: 0.0022\n",
            "r_precision: 0.0023\n",
            "recall_at_005: 0.0001\n",
            "recall_at_010: 0.0001\n",
            "recall_at_020: 0.0002\n",
            "recall_at_050: 0.0022\n",
            "recall_at_100: 0.0040\n",
            "## retrieve_eval img2phrase on train ##\n",
            "mean_average_precision: 0.0178\n",
            "mean_reciprocal_rank: 0.0201\n",
            "precision_at_005: 0.0005\n",
            "precision_at_010: 0.0005\n",
            "precision_at_020: 0.0017\n",
            "precision_at_050: 0.0084\n",
            "precision_at_100: 0.0096\n",
            "r_precision: 0.0021\n",
            "recall_at_005: 0.0012\n",
            "recall_at_010: 0.0023\n",
            "recall_at_020: 0.0154\n",
            "recall_at_050: 0.2515\n",
            "recall_at_100: 0.6424\n",
            "EVAL: since last best: 10\n",
            "EVAL: lr decay triggered\n",
            "STAT pred_scores: shape torch.Size([432, 655]) device cpu; mean -33.996; min -123.726; max -12.228; std 8.149\n",
            "## retrieve_eval phrase2img on train ##\n",
            "mean_average_precision: 0.0028\n",
            "mean_reciprocal_rank: 0.0032\n",
            "precision_at_005: 0.0018\n",
            "precision_at_010: 0.0018\n",
            "precision_at_020: 0.0024\n",
            "precision_at_050: 0.0024\n",
            "precision_at_100: 0.0027\n",
            "r_precision: 0.0023\n",
            "recall_at_005: 0.0000\n",
            "recall_at_010: 0.0001\n",
            "recall_at_020: 0.0018\n",
            "recall_at_050: 0.0042\n",
            "recall_at_100: 0.0121\n",
            "## retrieve_eval img2phrase on train ##\n",
            "mean_average_precision: 0.0783\n",
            "mean_reciprocal_rank: 0.0995\n",
            "precision_at_005: 0.0236\n",
            "precision_at_010: 0.0525\n",
            "precision_at_020: 0.0431\n",
            "precision_at_050: 0.0194\n",
            "precision_at_100: 0.0132\n",
            "r_precision: 0.0021\n",
            "recall_at_005: 0.0629\n",
            "recall_at_010: 0.3094\n",
            "recall_at_020: 0.5926\n",
            "recall_at_050: 0.6443\n",
            "recall_at_100: 0.8256\n",
            "EVAL: since last best: 11\n",
            "STAT pred_scores: shape torch.Size([432, 655]) device cpu; mean -34.697; min -119.926; max -12.337; std 7.646\n",
            "## retrieve_eval phrase2img on train ##\n",
            "mean_average_precision: 0.0029\n",
            "mean_reciprocal_rank: 0.0028\n",
            "precision_at_005: 0.0021\n",
            "precision_at_010: 0.0023\n",
            "precision_at_020: 0.0024\n",
            "precision_at_050: 0.0023\n",
            "precision_at_100: 0.0027\n",
            "r_precision: 0.0023\n",
            "recall_at_005: 0.0001\n",
            "recall_at_010: 0.0001\n",
            "recall_at_020: 0.0006\n",
            "recall_at_050: 0.0066\n",
            "recall_at_100: 0.0161\n",
            "## retrieve_eval img2phrase on train ##\n",
            "mean_average_precision: 0.3327\n",
            "mean_reciprocal_rank: 0.5137\n",
            "precision_at_005: 0.1042\n",
            "precision_at_010: 0.0537\n",
            "precision_at_020: 0.0483\n",
            "precision_at_050: 0.0204\n",
            "precision_at_100: 0.0133\n",
            "r_precision: 0.0021\n",
            "recall_at_005: 0.3086\n",
            "recall_at_010: 0.3221\n",
            "recall_at_020: 0.6435\n",
            "recall_at_050: 0.6659\n",
            "recall_at_100: 0.8306\n",
            "EVAL: since last best: 12\n",
            "STAT pred_scores: shape torch.Size([432, 655]) device cpu; mean -32.052; min -90.350; max -11.557; std 6.946\n",
            "## retrieve_eval phrase2img on train ##\n",
            "mean_average_precision: 0.0031\n",
            "mean_reciprocal_rank: 0.0034\n",
            "precision_at_005: 0.0021\n",
            "precision_at_010: 0.0023\n",
            "precision_at_020: 0.0027\n",
            "precision_at_050: 0.0027\n",
            "precision_at_100: 0.0031\n",
            "r_precision: 0.0023\n",
            "recall_at_005: 0.0001\n",
            "recall_at_010: 0.0001\n",
            "recall_at_020: 0.0005\n",
            "recall_at_050: 0.0043\n",
            "recall_at_100: 0.0137\n",
            "## retrieve_eval img2phrase on train ##\n",
            "mean_average_precision: 0.4835\n",
            "mean_reciprocal_rank: 0.6247\n",
            "precision_at_005: 0.1824\n",
            "precision_at_010: 0.0944\n",
            "precision_at_020: 0.0483\n",
            "precision_at_050: 0.0204\n",
            "precision_at_100: 0.0135\n",
            "r_precision: 0.0021\n",
            "recall_at_005: 0.6196\n",
            "recall_at_010: 0.6343\n",
            "recall_at_020: 0.6435\n",
            "recall_at_050: 0.6651\n",
            "recall_at_100: 0.8407\n",
            "EVAL: since last best: 13\n",
            "STAT pos_dist: shape torch.Size([16]) device cuda:0; mean 11.484; min 8.217; max 17.115; std 2.432\n",
            "STAT neg_img_dist: shape torch.Size([16]) device cuda:0; mean 19.517; min 14.608; max 25.660; std 2.851\n",
            "STAT neg_sent_dist: shape torch.Size([16]) device cuda:0; mean 26.731; min 19.693; max 31.825; std 3.447\n",
            "[02/10 16:34:22] epoch-2 step-300: loss 0.0000 (neg_img: 0.0000, neg_lang: 0.0000); lr 1.0E-05\n",
            "STAT pred_scores: shape torch.Size([432, 655]) device cpu; mean -30.673; min -81.987; max -10.870; std 6.520\n",
            "## retrieve_eval phrase2img on train ##\n",
            "mean_average_precision: 0.0031\n",
            "mean_reciprocal_rank: 0.0030\n",
            "precision_at_005: 0.0024\n",
            "precision_at_010: 0.0021\n",
            "precision_at_020: 0.0027\n",
            "precision_at_050: 0.0029\n",
            "precision_at_100: 0.0030\n",
            "r_precision: 0.0023\n",
            "recall_at_005: 0.0001\n",
            "recall_at_010: 0.0001\n",
            "recall_at_020: 0.0019\n",
            "recall_at_050: 0.0043\n",
            "recall_at_100: 0.0130\n",
            "## retrieve_eval img2phrase on train ##\n",
            "mean_average_precision: 0.5183\n",
            "mean_reciprocal_rank: 0.6282\n",
            "precision_at_005: 0.1847\n",
            "precision_at_010: 0.0954\n",
            "precision_at_020: 0.0596\n",
            "precision_at_050: 0.0267\n",
            "precision_at_100: 0.0135\n",
            "r_precision: 0.0021\n",
            "recall_at_005: 0.6254\n",
            "recall_at_010: 0.6385\n",
            "recall_at_020: 0.7635\n",
            "recall_at_050: 0.8299\n",
            "recall_at_100: 0.8372\n",
            "EVAL: since last best: 14\n",
            "STAT pred_scores: shape torch.Size([432, 655]) device cpu; mean -28.842; min -92.877; max -9.942; std 6.538\n",
            "## retrieve_eval phrase2img on train ##\n",
            "mean_average_precision: 0.0032\n",
            "mean_reciprocal_rank: 0.0035\n",
            "precision_at_005: 0.0018\n",
            "precision_at_010: 0.0021\n",
            "precision_at_020: 0.0030\n",
            "precision_at_050: 0.0027\n",
            "precision_at_100: 0.0031\n",
            "r_precision: 0.0023\n",
            "recall_at_005: 0.0000\n",
            "recall_at_010: 0.0001\n",
            "recall_at_020: 0.0021\n",
            "recall_at_050: 0.0045\n",
            "recall_at_100: 0.0174\n",
            "## retrieve_eval img2phrase on train ##\n",
            "mean_average_precision: 0.5385\n",
            "mean_reciprocal_rank: 0.6387\n",
            "precision_at_005: 0.1847\n",
            "precision_at_010: 0.0942\n",
            "precision_at_020: 0.0624\n",
            "precision_at_050: 0.0270\n",
            "precision_at_100: 0.0136\n",
            "r_precision: 0.0021\n",
            "recall_at_005: 0.6242\n",
            "recall_at_010: 0.6331\n",
            "recall_at_020: 0.7913\n",
            "recall_at_050: 0.8387\n",
            "recall_at_100: 0.8438\n",
            "EVAL: since last best: 15\n",
            "STAT pred_scores: shape torch.Size([432, 655]) device cpu; mean -30.207; min -69.958; max -10.046; std 6.313\n",
            "## retrieve_eval phrase2img on train ##\n",
            "mean_average_precision: 0.0031\n",
            "mean_reciprocal_rank: 0.0034\n",
            "precision_at_005: 0.0018\n",
            "precision_at_010: 0.0018\n",
            "precision_at_020: 0.0021\n",
            "precision_at_050: 0.0025\n",
            "precision_at_100: 0.0028\n",
            "r_precision: 0.0023\n",
            "recall_at_005: 0.0001\n",
            "recall_at_010: 0.0017\n",
            "recall_at_020: 0.0022\n",
            "recall_at_050: 0.0082\n",
            "recall_at_100: 0.0153\n",
            "## retrieve_eval img2phrase on train ##\n",
            "mean_average_precision: 0.5241\n",
            "mean_reciprocal_rank: 0.6271\n",
            "precision_at_005: 0.1852\n",
            "precision_at_010: 0.0961\n",
            "precision_at_020: 0.0494\n",
            "precision_at_050: 0.0272\n",
            "precision_at_100: 0.0138\n",
            "r_precision: 0.0021\n",
            "recall_at_005: 0.6265\n",
            "recall_at_010: 0.6420\n",
            "recall_at_020: 0.6532\n",
            "recall_at_050: 0.8414\n",
            "recall_at_100: 0.8488\n",
            "EVAL: since last best: 16\n",
            "STAT pred_scores: shape torch.Size([432, 655]) device cpu; mean -31.346; min -50.474; max -10.366; std 5.946\n",
            "## retrieve_eval phrase2img on train ##\n",
            "mean_average_precision: 0.0035\n",
            "mean_reciprocal_rank: 0.0035\n",
            "precision_at_005: 0.0018\n",
            "precision_at_010: 0.0023\n",
            "precision_at_020: 0.0028\n",
            "precision_at_050: 0.0032\n",
            "precision_at_100: 0.0034\n",
            "r_precision: 0.0023\n",
            "recall_at_005: 0.0000\n",
            "recall_at_010: 0.0004\n",
            "recall_at_020: 0.0030\n",
            "recall_at_050: 0.0061\n",
            "recall_at_100: 0.0161\n",
            "## retrieve_eval img2phrase on train ##\n",
            "mean_average_precision: 0.5587\n",
            "mean_reciprocal_rank: 0.6369\n",
            "precision_at_005: 0.2120\n",
            "precision_at_010: 0.1257\n",
            "precision_at_020: 0.0637\n",
            "precision_at_050: 0.0273\n",
            "precision_at_100: 0.0138\n",
            "r_precision: 0.0021\n",
            "recall_at_005: 0.6964\n",
            "recall_at_010: 0.7986\n",
            "recall_at_020: 0.8052\n",
            "recall_at_050: 0.8457\n",
            "recall_at_100: 0.8495\n",
            "EVAL: since last best: 17\n",
            "STAT pos_dist: shape torch.Size([16]) device cuda:0; mean 11.426; min 8.308; max 16.979; std 2.463\n",
            "STAT neg_img_dist: shape torch.Size([16]) device cuda:0; mean 15.862; min 12.040; max 21.668; std 2.720\n",
            "STAT neg_sent_dist: shape torch.Size([16]) device cuda:0; mean 28.027; min 18.667; max 36.037; std 5.816\n",
            "[02/10 16:39:22] epoch-2 step-350: loss 0.0000 (neg_img: 0.0000, neg_lang: 0.0000); lr 1.0E-05\n",
            "STAT pred_scores: shape torch.Size([432, 655]) device cpu; mean -30.980; min -49.827; max -10.319; std 5.881\n",
            "## retrieve_eval phrase2img on train ##\n",
            "mean_average_precision: 0.0035\n",
            "mean_reciprocal_rank: 0.0046\n",
            "precision_at_005: 0.0024\n",
            "precision_at_010: 0.0024\n",
            "precision_at_020: 0.0027\n",
            "precision_at_050: 0.0034\n",
            "precision_at_100: 0.0034\n",
            "r_precision: 0.0023\n",
            "recall_at_005: 0.0003\n",
            "recall_at_010: 0.0004\n",
            "recall_at_020: 0.0022\n",
            "recall_at_050: 0.0040\n",
            "recall_at_100: 0.0191\n",
            "## retrieve_eval img2phrase on train ##\n",
            "mean_average_precision: 0.6136\n",
            "mean_reciprocal_rank: 0.6593\n",
            "precision_at_005: 0.2481\n",
            "precision_at_010: 0.1259\n",
            "precision_at_020: 0.0649\n",
            "precision_at_050: 0.0273\n",
            "precision_at_100: 0.0138\n",
            "r_precision: 0.0021\n",
            "recall_at_005: 0.7913\n",
            "recall_at_010: 0.7994\n",
            "recall_at_020: 0.8152\n",
            "recall_at_050: 0.8457\n",
            "recall_at_100: 0.8495\n",
            "EVAL: since last best: 18\n",
            "STAT pred_scores: shape torch.Size([432, 655]) device cpu; mean -33.340; min -51.277; max -10.859; std 5.851\n",
            "## retrieve_eval phrase2img on train ##\n",
            "mean_average_precision: 0.0038\n",
            "mean_reciprocal_rank: 0.0051\n",
            "precision_at_005: 0.0027\n",
            "precision_at_010: 0.0027\n",
            "precision_at_020: 0.0031\n",
            "precision_at_050: 0.0035\n",
            "precision_at_100: 0.0036\n",
            "r_precision: 0.0023\n",
            "recall_at_005: 0.0011\n",
            "recall_at_010: 0.0013\n",
            "recall_at_020: 0.0031\n",
            "recall_at_050: 0.0047\n",
            "recall_at_100: 0.0165\n",
            "## retrieve_eval img2phrase on train ##\n",
            "mean_average_precision: 0.5628\n",
            "mean_reciprocal_rank: 0.6397\n",
            "precision_at_005: 0.2116\n",
            "precision_at_010: 0.1262\n",
            "precision_at_020: 0.0635\n",
            "precision_at_050: 0.0272\n",
            "precision_at_100: 0.0137\n",
            "r_precision: 0.0021\n",
            "recall_at_005: 0.6952\n",
            "recall_at_010: 0.8009\n",
            "recall_at_020: 0.8044\n",
            "recall_at_050: 0.8422\n",
            "recall_at_100: 0.8457\n",
            "EVAL: since last best: 19\n",
            "STAT pred_scores: shape torch.Size([432, 655]) device cpu; mean -32.158; min -59.160; max -12.042; std 5.652\n",
            "## retrieve_eval phrase2img on train ##\n",
            "mean_average_precision: 0.0036\n",
            "mean_reciprocal_rank: 0.0046\n",
            "precision_at_005: 0.0027\n",
            "precision_at_010: 0.0026\n",
            "precision_at_020: 0.0033\n",
            "precision_at_050: 0.0035\n",
            "precision_at_100: 0.0035\n",
            "r_precision: 0.0023\n",
            "recall_at_005: 0.0003\n",
            "recall_at_010: 0.0005\n",
            "recall_at_020: 0.0025\n",
            "recall_at_050: 0.0046\n",
            "recall_at_100: 0.0159\n",
            "## retrieve_eval img2phrase on train ##\n",
            "mean_average_precision: 0.6715\n",
            "mean_reciprocal_rank: 0.7157\n",
            "precision_at_005: 0.2454\n",
            "precision_at_010: 0.1259\n",
            "precision_at_020: 0.0635\n",
            "precision_at_050: 0.0270\n",
            "precision_at_100: 0.0136\n",
            "r_precision: 0.0021\n",
            "recall_at_005: 0.7855\n",
            "recall_at_010: 0.7994\n",
            "recall_at_020: 0.8044\n",
            "recall_at_050: 0.8383\n",
            "recall_at_100: 0.8445\n",
            "EVAL: new best!\n",
            "STAT pred_scores: shape torch.Size([432, 655]) device cpu; mean -33.260; min -57.401; max -12.548; std 5.761\n",
            "## retrieve_eval phrase2img on train ##\n",
            "mean_average_precision: 0.0037\n",
            "mean_reciprocal_rank: 0.0049\n",
            "precision_at_005: 0.0021\n",
            "precision_at_010: 0.0024\n",
            "precision_at_020: 0.0031\n",
            "precision_at_050: 0.0035\n",
            "precision_at_100: 0.0036\n",
            "r_precision: 0.0023\n",
            "recall_at_005: 0.0003\n",
            "recall_at_010: 0.0005\n",
            "recall_at_020: 0.0025\n",
            "recall_at_050: 0.0054\n",
            "recall_at_100: 0.0159\n",
            "## retrieve_eval img2phrase on train ##\n",
            "mean_average_precision: 0.6583\n",
            "mean_reciprocal_rank: 0.7093\n",
            "precision_at_005: 0.2463\n",
            "precision_at_010: 0.1259\n",
            "precision_at_020: 0.0635\n",
            "precision_at_050: 0.0270\n",
            "precision_at_100: 0.0137\n",
            "r_precision: 0.0021\n",
            "recall_at_005: 0.7874\n",
            "recall_at_010: 0.7994\n",
            "recall_at_020: 0.8044\n",
            "recall_at_050: 0.8383\n",
            "recall_at_100: 0.8457\n",
            "EVAL: since last best: 1\n",
            "STAT pred_scores: shape torch.Size([432, 655]) device cpu; mean -32.640; min -54.645; max -12.252; std 5.632\n",
            "## retrieve_eval phrase2img on train ##\n",
            "mean_average_precision: 0.0039\n",
            "mean_reciprocal_rank: 0.0058\n",
            "precision_at_005: 0.0024\n",
            "precision_at_010: 0.0027\n",
            "precision_at_020: 0.0034\n",
            "precision_at_050: 0.0035\n",
            "precision_at_100: 0.0037\n",
            "r_precision: 0.0023\n",
            "recall_at_005: 0.0003\n",
            "recall_at_010: 0.0005\n",
            "recall_at_020: 0.0025\n",
            "recall_at_050: 0.0055\n",
            "recall_at_100: 0.0145\n",
            "## retrieve_eval img2phrase on train ##\n",
            "mean_average_precision: 0.6668\n",
            "mean_reciprocal_rank: 0.7185\n",
            "precision_at_005: 0.2458\n",
            "precision_at_010: 0.1259\n",
            "precision_at_020: 0.0635\n",
            "precision_at_050: 0.0270\n",
            "precision_at_100: 0.0136\n",
            "r_precision: 0.0021\n",
            "recall_at_005: 0.7863\n",
            "recall_at_010: 0.7994\n",
            "recall_at_020: 0.8044\n",
            "recall_at_050: 0.8383\n",
            "recall_at_100: 0.8445\n",
            "EVAL: since last best: 2\n",
            "STAT pos_dist: shape torch.Size([16]) device cuda:0; mean 10.444; min 7.193; max 13.447; std 1.853\n",
            "STAT neg_img_dist: shape torch.Size([16]) device cuda:0; mean 17.988; min 15.298; max 21.918; std 2.067\n",
            "STAT neg_sent_dist: shape torch.Size([16]) device cuda:0; mean 30.823; min 19.172; max 38.360; std 5.186\n",
            "[02/10 16:45:11] epoch-2 step-400: loss 0.0000 (neg_img: 0.0000, neg_lang: 0.0000); lr 1.0E-05\n",
            "STAT pred_scores: shape torch.Size([432, 655]) device cpu; mean -32.121; min -69.303; max -12.263; std 5.738\n",
            "## retrieve_eval phrase2img on train ##\n",
            "mean_average_precision: 0.0036\n",
            "mean_reciprocal_rank: 0.0040\n",
            "precision_at_005: 0.0027\n",
            "precision_at_010: 0.0023\n",
            "precision_at_020: 0.0031\n",
            "precision_at_050: 0.0037\n",
            "precision_at_100: 0.0037\n",
            "r_precision: 0.0023\n",
            "recall_at_005: 0.0001\n",
            "recall_at_010: 0.0003\n",
            "recall_at_020: 0.0026\n",
            "recall_at_050: 0.0104\n",
            "recall_at_100: 0.0181\n",
            "## retrieve_eval img2phrase on train ##\n",
            "mean_average_precision: 0.6385\n",
            "mean_reciprocal_rank: 0.6932\n",
            "precision_at_005: 0.2454\n",
            "precision_at_010: 0.1259\n",
            "precision_at_020: 0.0635\n",
            "precision_at_050: 0.0270\n",
            "precision_at_100: 0.0136\n",
            "r_precision: 0.0021\n",
            "recall_at_005: 0.7851\n",
            "recall_at_010: 0.7994\n",
            "recall_at_020: 0.8044\n",
            "recall_at_050: 0.8383\n",
            "recall_at_100: 0.8445\n",
            "EVAL: since last best: 3\n",
            "STAT pred_scores: shape torch.Size([432, 655]) device cpu; mean -32.639; min -60.417; max -12.362; std 5.792\n",
            "## retrieve_eval phrase2img on train ##\n",
            "mean_average_precision: 0.0037\n",
            "mean_reciprocal_rank: 0.0044\n",
            "precision_at_005: 0.0031\n",
            "precision_at_010: 0.0029\n",
            "precision_at_020: 0.0032\n",
            "precision_at_050: 0.0036\n",
            "precision_at_100: 0.0038\n",
            "r_precision: 0.0023\n",
            "recall_at_005: 0.0003\n",
            "recall_at_010: 0.0005\n",
            "recall_at_020: 0.0025\n",
            "recall_at_050: 0.0057\n",
            "recall_at_100: 0.0167\n",
            "## retrieve_eval img2phrase on train ##\n",
            "mean_average_precision: 0.5669\n",
            "mean_reciprocal_rank: 0.6417\n",
            "precision_at_005: 0.2417\n",
            "precision_at_010: 0.1259\n",
            "precision_at_020: 0.0634\n",
            "precision_at_050: 0.0270\n",
            "precision_at_100: 0.0136\n",
            "r_precision: 0.0021\n",
            "recall_at_005: 0.7747\n",
            "recall_at_010: 0.7994\n",
            "recall_at_020: 0.8036\n",
            "recall_at_050: 0.8376\n",
            "recall_at_100: 0.8445\n",
            "EVAL: since last best: 4\n",
            "STAT pred_scores: shape torch.Size([432, 655]) device cpu; mean -29.470; min -62.298; max -13.350; std 4.877\n",
            "## retrieve_eval phrase2img on train ##\n",
            "mean_average_precision: 0.0037\n",
            "mean_reciprocal_rank: 0.0044\n",
            "precision_at_005: 0.0021\n",
            "precision_at_010: 0.0024\n",
            "precision_at_020: 0.0031\n",
            "precision_at_050: 0.0035\n",
            "precision_at_100: 0.0037\n",
            "r_precision: 0.0023\n",
            "recall_at_005: 0.0001\n",
            "recall_at_010: 0.0005\n",
            "recall_at_020: 0.0023\n",
            "recall_at_050: 0.0054\n",
            "recall_at_100: 0.0149\n",
            "## retrieve_eval img2phrase on train ##\n",
            "mean_average_precision: 0.5288\n",
            "mean_reciprocal_rank: 0.6215\n",
            "precision_at_005: 0.2407\n",
            "precision_at_010: 0.1245\n",
            "precision_at_020: 0.0633\n",
            "precision_at_050: 0.0271\n",
            "precision_at_100: 0.0138\n",
            "r_precision: 0.0021\n",
            "recall_at_005: 0.7739\n",
            "recall_at_010: 0.7932\n",
            "recall_at_020: 0.8025\n",
            "recall_at_050: 0.8403\n",
            "recall_at_100: 0.8507\n",
            "EVAL: since last best: 5\n",
            "STAT pred_scores: shape torch.Size([432, 655]) device cpu; mean -28.311; min -65.223; max -12.894; std 5.185\n",
            "## retrieve_eval phrase2img on train ##\n",
            "mean_average_precision: 0.0036\n",
            "mean_reciprocal_rank: 0.0036\n",
            "precision_at_005: 0.0021\n",
            "precision_at_010: 0.0024\n",
            "precision_at_020: 0.0030\n",
            "precision_at_050: 0.0035\n",
            "precision_at_100: 0.0037\n",
            "r_precision: 0.0023\n",
            "recall_at_005: 0.0001\n",
            "recall_at_010: 0.0003\n",
            "recall_at_020: 0.0022\n",
            "recall_at_050: 0.0052\n",
            "recall_at_100: 0.0148\n",
            "## retrieve_eval img2phrase on train ##\n",
            "mean_average_precision: 0.5545\n",
            "mean_reciprocal_rank: 0.6376\n",
            "precision_at_005: 0.2435\n",
            "precision_at_010: 0.1241\n",
            "precision_at_020: 0.0656\n",
            "precision_at_050: 0.0276\n",
            "precision_at_100: 0.0138\n",
            "r_precision: 0.0021\n",
            "recall_at_005: 0.7805\n",
            "recall_at_010: 0.7913\n",
            "recall_at_020: 0.8202\n",
            "recall_at_050: 0.8507\n",
            "recall_at_100: 0.8519\n",
            "EVAL: since last best: 6\n",
            "STAT pos_dist: shape torch.Size([16]) device cuda:0; mean 9.943; min 7.980; max 12.840; std 1.352\n",
            "STAT neg_img_dist: shape torch.Size([16]) device cuda:0; mean 18.256; min 16.065; max 25.156; std 2.720\n",
            "STAT neg_sent_dist: shape torch.Size([16]) device cuda:0; mean 24.790; min 19.299; max 30.999; std 3.812\n",
            "[02/10 16:50:10] epoch-2 step-450: loss 0.0000 (neg_img: 0.0000, neg_lang: 0.0000); lr 1.0E-05\n",
            "STAT pred_scores: shape torch.Size([432, 655]) device cpu; mean -28.442; min -70.741; max -13.023; std 5.332\n",
            "## retrieve_eval phrase2img on train ##\n",
            "mean_average_precision: 0.0036\n",
            "mean_reciprocal_rank: 0.0037\n",
            "precision_at_005: 0.0024\n",
            "precision_at_010: 0.0027\n",
            "precision_at_020: 0.0030\n",
            "precision_at_050: 0.0034\n",
            "precision_at_100: 0.0037\n",
            "r_precision: 0.0023\n",
            "recall_at_005: 0.0001\n",
            "recall_at_010: 0.0005\n",
            "recall_at_020: 0.0022\n",
            "recall_at_050: 0.0052\n",
            "recall_at_100: 0.0157\n",
            "## retrieve_eval img2phrase on train ##\n",
            "mean_average_precision: 0.5537\n",
            "mean_reciprocal_rank: 0.6346\n",
            "precision_at_005: 0.2440\n",
            "precision_at_010: 0.1248\n",
            "precision_at_020: 0.0661\n",
            "precision_at_050: 0.0276\n",
            "precision_at_100: 0.0138\n",
            "r_precision: 0.0021\n",
            "recall_at_005: 0.7816\n",
            "recall_at_010: 0.7936\n",
            "recall_at_020: 0.8237\n",
            "recall_at_050: 0.8507\n",
            "recall_at_100: 0.8519\n",
            "EVAL: since last best: 7\n",
            "STAT pred_scores: shape torch.Size([432, 655]) device cpu; mean -28.530; min -63.122; max -12.281; std 5.207\n",
            "## retrieve_eval phrase2img on train ##\n",
            "mean_average_precision: 0.0035\n",
            "mean_reciprocal_rank: 0.0044\n",
            "precision_at_005: 0.0027\n",
            "precision_at_010: 0.0026\n",
            "precision_at_020: 0.0029\n",
            "precision_at_050: 0.0033\n",
            "precision_at_100: 0.0035\n",
            "r_precision: 0.0023\n",
            "recall_at_005: 0.0003\n",
            "recall_at_010: 0.0004\n",
            "recall_at_020: 0.0010\n",
            "recall_at_050: 0.0043\n",
            "recall_at_100: 0.0148\n",
            "## retrieve_eval img2phrase on train ##\n",
            "mean_average_precision: 0.5552\n",
            "mean_reciprocal_rank: 0.6365\n",
            "precision_at_005: 0.2449\n",
            "precision_at_010: 0.1245\n",
            "precision_at_020: 0.0666\n",
            "precision_at_050: 0.0276\n",
            "precision_at_100: 0.0138\n",
            "r_precision: 0.0021\n",
            "recall_at_005: 0.7836\n",
            "recall_at_010: 0.7928\n",
            "recall_at_020: 0.8272\n",
            "recall_at_050: 0.8507\n",
            "recall_at_100: 0.8519\n",
            "EVAL: since last best: 8\n",
            "STAT pred_scores: shape torch.Size([432, 655]) device cpu; mean -30.511; min -54.639; max -12.856; std 5.324\n",
            "## retrieve_eval phrase2img on train ##\n",
            "mean_average_precision: 0.0037\n",
            "mean_reciprocal_rank: 0.0038\n",
            "precision_at_005: 0.0024\n",
            "precision_at_010: 0.0026\n",
            "precision_at_020: 0.0031\n",
            "precision_at_050: 0.0035\n",
            "precision_at_100: 0.0036\n",
            "r_precision: 0.0023\n",
            "recall_at_005: 0.0003\n",
            "recall_at_010: 0.0004\n",
            "recall_at_020: 0.0025\n",
            "recall_at_050: 0.0039\n",
            "recall_at_100: 0.0140\n",
            "## retrieve_eval img2phrase on train ##\n",
            "mean_average_precision: 0.5658\n",
            "mean_reciprocal_rank: 0.6447\n",
            "precision_at_005: 0.2435\n",
            "precision_at_010: 0.1250\n",
            "precision_at_020: 0.0667\n",
            "precision_at_050: 0.0276\n",
            "precision_at_100: 0.0138\n",
            "r_precision: 0.0021\n",
            "recall_at_005: 0.7805\n",
            "recall_at_010: 0.7944\n",
            "recall_at_020: 0.8283\n",
            "recall_at_050: 0.8507\n",
            "recall_at_100: 0.8519\n",
            "EVAL: since last best: 9\n",
            "STAT pred_scores: shape torch.Size([432, 655]) device cpu; mean -28.281; min -62.867; max -11.972; std 5.230\n",
            "## retrieve_eval phrase2img on train ##\n",
            "mean_average_precision: 0.0037\n",
            "mean_reciprocal_rank: 0.0042\n",
            "precision_at_005: 0.0024\n",
            "precision_at_010: 0.0027\n",
            "precision_at_020: 0.0033\n",
            "precision_at_050: 0.0034\n",
            "precision_at_100: 0.0037\n",
            "r_precision: 0.0023\n",
            "recall_at_005: 0.0001\n",
            "recall_at_010: 0.0002\n",
            "recall_at_020: 0.0025\n",
            "recall_at_050: 0.0052\n",
            "recall_at_100: 0.0172\n",
            "## retrieve_eval img2phrase on train ##\n",
            "mean_average_precision: 0.5877\n",
            "mean_reciprocal_rank: 0.6627\n",
            "precision_at_005: 0.2435\n",
            "precision_at_010: 0.1259\n",
            "precision_at_020: 0.0669\n",
            "precision_at_050: 0.0276\n",
            "precision_at_100: 0.0138\n",
            "r_precision: 0.0021\n",
            "recall_at_005: 0.7805\n",
            "recall_at_010: 0.7978\n",
            "recall_at_020: 0.8302\n",
            "recall_at_050: 0.8507\n",
            "recall_at_100: 0.8519\n",
            "EVAL: since last best: 10\n",
            "EVAL: lr decay triggered\n",
            "STAT pos_dist: shape torch.Size([16]) device cuda:0; mean 11.775; min 7.770; max 17.316; std 2.734\n",
            "STAT neg_img_dist: shape torch.Size([16]) device cuda:0; mean 18.420; min 13.937; max 23.933; std 3.376\n",
            "STAT neg_sent_dist: shape torch.Size([16]) device cuda:0; mean 25.536; min 16.314; max 37.090; std 5.263\n",
            "[02/10 16:55:14] epoch-3 step-500: loss 0.0000 (neg_img: 0.0000, neg_lang: 0.0000); lr 1.0E-06\n",
            "STAT pred_scores: shape torch.Size([432, 655]) device cpu; mean -29.396; min -62.243; max -12.604; std 5.335\n",
            "## retrieve_eval phrase2img on train ##\n",
            "mean_average_precision: 0.0038\n",
            "mean_reciprocal_rank: 0.0045\n",
            "precision_at_005: 0.0024\n",
            "precision_at_010: 0.0032\n",
            "precision_at_020: 0.0035\n",
            "precision_at_050: 0.0037\n",
            "precision_at_100: 0.0038\n",
            "r_precision: 0.0023\n",
            "recall_at_005: 0.0001\n",
            "recall_at_010: 0.0006\n",
            "recall_at_020: 0.0026\n",
            "recall_at_050: 0.0056\n",
            "recall_at_100: 0.0185\n",
            "## retrieve_eval img2phrase on train ##\n",
            "mean_average_precision: 0.5705\n",
            "mean_reciprocal_rank: 0.6474\n",
            "precision_at_005: 0.2421\n",
            "precision_at_010: 0.1262\n",
            "precision_at_020: 0.0669\n",
            "precision_at_050: 0.0276\n",
            "precision_at_100: 0.0138\n",
            "r_precision: 0.0021\n",
            "recall_at_005: 0.7770\n",
            "recall_at_010: 0.7990\n",
            "recall_at_020: 0.8302\n",
            "recall_at_050: 0.8507\n",
            "recall_at_100: 0.8519\n",
            "EVAL: since last best: 11\n",
            "STAT pred_scores: shape torch.Size([432, 655]) device cpu; mean -29.375; min -58.167; max -12.577; std 5.299\n",
            "## retrieve_eval phrase2img on train ##\n",
            "mean_average_precision: 0.0038\n",
            "mean_reciprocal_rank: 0.0045\n",
            "precision_at_005: 0.0024\n",
            "precision_at_010: 0.0027\n",
            "precision_at_020: 0.0034\n",
            "precision_at_050: 0.0035\n",
            "precision_at_100: 0.0038\n",
            "r_precision: 0.0023\n",
            "recall_at_005: 0.0001\n",
            "recall_at_010: 0.0004\n",
            "recall_at_020: 0.0026\n",
            "recall_at_050: 0.0053\n",
            "recall_at_100: 0.0183\n",
            "## retrieve_eval img2phrase on train ##\n",
            "mean_average_precision: 0.5772\n",
            "mean_reciprocal_rank: 0.6523\n",
            "precision_at_005: 0.2444\n",
            "precision_at_010: 0.1259\n",
            "precision_at_020: 0.0669\n",
            "precision_at_050: 0.0276\n",
            "precision_at_100: 0.0138\n",
            "r_precision: 0.0021\n",
            "recall_at_005: 0.7828\n",
            "recall_at_010: 0.7978\n",
            "recall_at_020: 0.8302\n",
            "recall_at_050: 0.8507\n",
            "recall_at_100: 0.8519\n",
            "EVAL: since last best: 12\n",
            "STAT pred_scores: shape torch.Size([432, 655]) device cpu; mean -29.076; min -63.915; max -12.405; std 5.325\n",
            "## retrieve_eval phrase2img on train ##\n",
            "mean_average_precision: 0.0038\n",
            "mean_reciprocal_rank: 0.0044\n",
            "precision_at_005: 0.0024\n",
            "precision_at_010: 0.0029\n",
            "precision_at_020: 0.0035\n",
            "precision_at_050: 0.0035\n",
            "precision_at_100: 0.0038\n",
            "r_precision: 0.0023\n",
            "recall_at_005: 0.0001\n",
            "recall_at_010: 0.0004\n",
            "recall_at_020: 0.0026\n",
            "recall_at_050: 0.0052\n",
            "recall_at_100: 0.0183\n",
            "## retrieve_eval img2phrase on train ##\n",
            "mean_average_precision: 0.5813\n",
            "mean_reciprocal_rank: 0.6543\n",
            "precision_at_005: 0.2444\n",
            "precision_at_010: 0.1259\n",
            "precision_at_020: 0.0669\n",
            "precision_at_050: 0.0276\n",
            "precision_at_100: 0.0138\n",
            "r_precision: 0.0021\n",
            "recall_at_005: 0.7828\n",
            "recall_at_010: 0.7978\n",
            "recall_at_020: 0.8302\n",
            "recall_at_050: 0.8507\n",
            "recall_at_100: 0.8519\n",
            "EVAL: since last best: 13\n",
            "STAT pred_scores: shape torch.Size([432, 655]) device cpu; mean -29.100; min -60.875; max -12.437; std 5.289\n",
            "## retrieve_eval phrase2img on train ##\n",
            "mean_average_precision: 0.0038\n",
            "mean_reciprocal_rank: 0.0044\n",
            "precision_at_005: 0.0027\n",
            "precision_at_010: 0.0029\n",
            "precision_at_020: 0.0034\n",
            "precision_at_050: 0.0035\n",
            "precision_at_100: 0.0038\n",
            "r_precision: 0.0023\n",
            "recall_at_005: 0.0001\n",
            "recall_at_010: 0.0004\n",
            "recall_at_020: 0.0025\n",
            "recall_at_050: 0.0054\n",
            "recall_at_100: 0.0184\n",
            "## retrieve_eval img2phrase on train ##\n",
            "mean_average_precision: 0.5818\n",
            "mean_reciprocal_rank: 0.6555\n",
            "precision_at_005: 0.2444\n",
            "precision_at_010: 0.1259\n",
            "precision_at_020: 0.0669\n",
            "precision_at_050: 0.0276\n",
            "precision_at_100: 0.0138\n",
            "r_precision: 0.0021\n",
            "recall_at_005: 0.7828\n",
            "recall_at_010: 0.7978\n",
            "recall_at_020: 0.8302\n",
            "recall_at_050: 0.8507\n",
            "recall_at_100: 0.8519\n",
            "EVAL: since last best: 14\n",
            "STAT pred_scores: shape torch.Size([432, 655]) device cpu; mean -29.149; min -57.408; max -12.542; std 5.253\n",
            "## retrieve_eval phrase2img on train ##\n",
            "mean_average_precision: 0.0037\n",
            "mean_reciprocal_rank: 0.0044\n",
            "precision_at_005: 0.0027\n",
            "precision_at_010: 0.0032\n",
            "precision_at_020: 0.0034\n",
            "precision_at_050: 0.0035\n",
            "precision_at_100: 0.0038\n",
            "r_precision: 0.0023\n",
            "recall_at_005: 0.0001\n",
            "recall_at_010: 0.0006\n",
            "recall_at_020: 0.0025\n",
            "recall_at_050: 0.0052\n",
            "recall_at_100: 0.0184\n",
            "## retrieve_eval img2phrase on train ##\n",
            "mean_average_precision: 0.5739\n",
            "mean_reciprocal_rank: 0.6501\n",
            "precision_at_005: 0.2431\n",
            "precision_at_010: 0.1262\n",
            "precision_at_020: 0.0669\n",
            "precision_at_050: 0.0276\n",
            "precision_at_100: 0.0138\n",
            "r_precision: 0.0021\n",
            "recall_at_005: 0.7793\n",
            "recall_at_010: 0.7990\n",
            "recall_at_020: 0.8302\n",
            "recall_at_050: 0.8507\n",
            "recall_at_100: 0.8519\n",
            "EVAL: since last best: 15\n",
            "STAT pos_dist: shape torch.Size([16]) device cuda:0; mean 10.938; min 7.582; max 14.193; std 1.972\n",
            "STAT neg_img_dist: shape torch.Size([16]) device cuda:0; mean 17.401; min 13.144; max 21.600; std 2.399\n",
            "STAT neg_sent_dist: shape torch.Size([16]) device cuda:0; mean 23.459; min 16.216; max 33.043; std 4.646\n",
            "[02/10 17:00:53] epoch-3 step-550: loss 0.0000 (neg_img: 0.0000, neg_lang: 0.0000); lr 1.0E-06\n",
            "STAT pred_scores: shape torch.Size([432, 655]) device cpu; mean -28.461; min -63.586; max -12.170; std 5.254\n",
            "## retrieve_eval phrase2img on train ##\n",
            "mean_average_precision: 0.0037\n",
            "mean_reciprocal_rank: 0.0043\n",
            "precision_at_005: 0.0024\n",
            "precision_at_010: 0.0027\n",
            "precision_at_020: 0.0033\n",
            "precision_at_050: 0.0036\n",
            "precision_at_100: 0.0037\n",
            "r_precision: 0.0023\n",
            "recall_at_005: 0.0001\n",
            "recall_at_010: 0.0002\n",
            "recall_at_020: 0.0025\n",
            "recall_at_050: 0.0041\n",
            "recall_at_100: 0.0185\n",
            "## retrieve_eval img2phrase on train ##\n",
            "mean_average_precision: 0.5854\n",
            "mean_reciprocal_rank: 0.6611\n",
            "precision_at_005: 0.2435\n",
            "precision_at_010: 0.1259\n",
            "precision_at_020: 0.0670\n",
            "precision_at_050: 0.0276\n",
            "precision_at_100: 0.0138\n",
            "r_precision: 0.0021\n",
            "recall_at_005: 0.7805\n",
            "recall_at_010: 0.7978\n",
            "recall_at_020: 0.8314\n",
            "recall_at_050: 0.8507\n",
            "recall_at_100: 0.8519\n",
            "EVAL: since last best: 16\n",
            "STAT pred_scores: shape torch.Size([432, 655]) device cpu; mean -28.768; min -55.975; max -12.231; std 5.209\n",
            "## retrieve_eval phrase2img on train ##\n",
            "mean_average_precision: 0.0037\n",
            "mean_reciprocal_rank: 0.0044\n",
            "precision_at_005: 0.0027\n",
            "precision_at_010: 0.0027\n",
            "precision_at_020: 0.0034\n",
            "precision_at_050: 0.0035\n",
            "precision_at_100: 0.0038\n",
            "r_precision: 0.0023\n",
            "recall_at_005: 0.0001\n",
            "recall_at_010: 0.0002\n",
            "recall_at_020: 0.0025\n",
            "recall_at_050: 0.0037\n",
            "recall_at_100: 0.0186\n",
            "## retrieve_eval img2phrase on train ##\n",
            "mean_average_precision: 0.5752\n",
            "mean_reciprocal_rank: 0.6528\n",
            "precision_at_005: 0.2435\n",
            "precision_at_010: 0.1259\n",
            "precision_at_020: 0.0669\n",
            "precision_at_050: 0.0276\n",
            "precision_at_100: 0.0138\n",
            "r_precision: 0.0021\n",
            "recall_at_005: 0.7805\n",
            "recall_at_010: 0.7978\n",
            "recall_at_020: 0.8302\n",
            "recall_at_050: 0.8507\n",
            "recall_at_100: 0.8519\n",
            "EVAL: since last best: 17\n",
            "STAT pred_scores: shape torch.Size([432, 655]) device cpu; mean -29.311; min -65.510; max -12.413; std 5.387\n",
            "## retrieve_eval phrase2img on train ##\n",
            "mean_average_precision: 0.0038\n",
            "mean_reciprocal_rank: 0.0045\n",
            "precision_at_005: 0.0027\n",
            "precision_at_010: 0.0031\n",
            "precision_at_020: 0.0036\n",
            "precision_at_050: 0.0036\n",
            "precision_at_100: 0.0038\n",
            "r_precision: 0.0023\n",
            "recall_at_005: 0.0001\n",
            "recall_at_010: 0.0003\n",
            "recall_at_020: 0.0029\n",
            "recall_at_050: 0.0040\n",
            "recall_at_100: 0.0182\n",
            "## retrieve_eval img2phrase on train ##\n",
            "mean_average_precision: 0.5736\n",
            "mean_reciprocal_rank: 0.6511\n",
            "precision_at_005: 0.2412\n",
            "precision_at_010: 0.1259\n",
            "precision_at_020: 0.0669\n",
            "precision_at_050: 0.0276\n",
            "precision_at_100: 0.0138\n",
            "r_precision: 0.0021\n",
            "recall_at_005: 0.7751\n",
            "recall_at_010: 0.7978\n",
            "recall_at_020: 0.8302\n",
            "recall_at_050: 0.8507\n",
            "recall_at_100: 0.8519\n",
            "EVAL: since last best: 18\n",
            "STAT pred_scores: shape torch.Size([432, 655]) device cpu; mean -28.903; min -68.138; max -12.215; std 5.388\n",
            "## retrieve_eval phrase2img on train ##\n",
            "mean_average_precision: 0.0038\n",
            "mean_reciprocal_rank: 0.0046\n",
            "precision_at_005: 0.0027\n",
            "precision_at_010: 0.0029\n",
            "precision_at_020: 0.0034\n",
            "precision_at_050: 0.0035\n",
            "precision_at_100: 0.0038\n",
            "r_precision: 0.0023\n",
            "recall_at_005: 0.0001\n",
            "recall_at_010: 0.0002\n",
            "recall_at_020: 0.0025\n",
            "recall_at_050: 0.0038\n",
            "recall_at_100: 0.0187\n",
            "## retrieve_eval img2phrase on train ##\n",
            "mean_average_precision: 0.5918\n",
            "mean_reciprocal_rank: 0.6638\n",
            "precision_at_005: 0.2435\n",
            "precision_at_010: 0.1262\n",
            "precision_at_020: 0.0670\n",
            "precision_at_050: 0.0276\n",
            "precision_at_100: 0.0138\n",
            "r_precision: 0.0021\n",
            "recall_at_005: 0.7793\n",
            "recall_at_010: 0.7990\n",
            "recall_at_020: 0.8314\n",
            "recall_at_050: 0.8507\n",
            "recall_at_100: 0.8519\n",
            "EVAL: since last best: 19\n",
            "STAT pos_dist: shape torch.Size([16]) device cuda:0; mean 13.422; min 9.988; max 20.189; std 2.559\n",
            "STAT neg_img_dist: shape torch.Size([16]) device cuda:0; mean 18.885; min 14.679; max 27.568; std 3.452\n",
            "STAT neg_sent_dist: shape torch.Size([16]) device cuda:0; mean 30.077; min 18.952; max 40.291; std 6.593\n",
            "[02/10 17:05:55] epoch-3 step-600: loss 0.0197 (neg_img: 0.0000, neg_lang: 0.0394); lr 1.0E-06\n",
            "STAT pred_scores: shape torch.Size([432, 655]) device cpu; mean -29.258; min -57.683; max -12.265; std 5.297\n",
            "## retrieve_eval phrase2img on train ##\n",
            "mean_average_precision: 0.0037\n",
            "mean_reciprocal_rank: 0.0044\n",
            "precision_at_005: 0.0027\n",
            "precision_at_010: 0.0031\n",
            "precision_at_020: 0.0034\n",
            "precision_at_050: 0.0035\n",
            "precision_at_100: 0.0037\n",
            "r_precision: 0.0023\n",
            "recall_at_005: 0.0001\n",
            "recall_at_010: 0.0003\n",
            "recall_at_020: 0.0026\n",
            "recall_at_050: 0.0037\n",
            "recall_at_100: 0.0185\n",
            "## retrieve_eval img2phrase on train ##\n",
            "mean_average_precision: 0.5840\n",
            "mean_reciprocal_rank: 0.6563\n",
            "precision_at_005: 0.2426\n",
            "precision_at_010: 0.1262\n",
            "precision_at_020: 0.0664\n",
            "precision_at_050: 0.0276\n",
            "precision_at_100: 0.0138\n",
            "r_precision: 0.0021\n",
            "recall_at_005: 0.7785\n",
            "recall_at_010: 0.7990\n",
            "recall_at_020: 0.8268\n",
            "recall_at_050: 0.8507\n",
            "recall_at_100: 0.8519\n",
            "EVAL: since last best: 20\n",
            "EVAL: lr decay triggered\n",
            "STAT pred_scores: shape torch.Size([432, 655]) device cpu; mean -28.914; min -57.305; max -12.101; std 5.260\n",
            "## retrieve_eval phrase2img on train ##\n",
            "mean_average_precision: 0.0037\n",
            "mean_reciprocal_rank: 0.0044\n",
            "precision_at_005: 0.0024\n",
            "precision_at_010: 0.0029\n",
            "precision_at_020: 0.0032\n",
            "precision_at_050: 0.0035\n",
            "precision_at_100: 0.0037\n",
            "r_precision: 0.0023\n",
            "recall_at_005: 0.0001\n",
            "recall_at_010: 0.0018\n",
            "recall_at_020: 0.0024\n",
            "recall_at_050: 0.0041\n",
            "recall_at_100: 0.0185\n",
            "## retrieve_eval img2phrase on train ##\n",
            "mean_average_precision: 0.5950\n",
            "mean_reciprocal_rank: 0.6645\n",
            "precision_at_005: 0.2444\n",
            "precision_at_010: 0.1259\n",
            "precision_at_020: 0.0666\n",
            "precision_at_050: 0.0276\n",
            "precision_at_100: 0.0138\n",
            "r_precision: 0.0021\n",
            "recall_at_005: 0.7828\n",
            "recall_at_010: 0.7982\n",
            "recall_at_020: 0.8275\n",
            "recall_at_050: 0.8507\n",
            "recall_at_100: 0.8519\n",
            "EVAL: since last best: 21\n",
            "STAT pred_scores: shape torch.Size([432, 655]) device cpu; mean -30.301; min -58.085; max -12.835; std 5.402\n",
            "## retrieve_eval phrase2img on train ##\n",
            "mean_average_precision: 0.0038\n",
            "mean_reciprocal_rank: 0.0048\n",
            "precision_at_005: 0.0027\n",
            "precision_at_010: 0.0031\n",
            "precision_at_020: 0.0035\n",
            "precision_at_050: 0.0036\n",
            "precision_at_100: 0.0037\n",
            "r_precision: 0.0023\n",
            "recall_at_005: 0.0003\n",
            "recall_at_010: 0.0006\n",
            "recall_at_020: 0.0029\n",
            "recall_at_050: 0.0041\n",
            "recall_at_100: 0.0177\n",
            "## retrieve_eval img2phrase on train ##\n",
            "mean_average_precision: 0.5773\n",
            "mean_reciprocal_rank: 0.6507\n",
            "precision_at_005: 0.2426\n",
            "precision_at_010: 0.1262\n",
            "precision_at_020: 0.0664\n",
            "precision_at_050: 0.0276\n",
            "precision_at_100: 0.0138\n",
            "r_precision: 0.0021\n",
            "recall_at_005: 0.7785\n",
            "recall_at_010: 0.7994\n",
            "recall_at_020: 0.8268\n",
            "recall_at_050: 0.8507\n",
            "recall_at_100: 0.8519\n",
            "EVAL: since last best: 22\n",
            "STAT pred_scores: shape torch.Size([432, 655]) device cpu; mean -29.390; min -63.481; max -12.404; std 5.354\n",
            "## retrieve_eval phrase2img on train ##\n",
            "mean_average_precision: 0.0038\n",
            "mean_reciprocal_rank: 0.0044\n",
            "precision_at_005: 0.0027\n",
            "precision_at_010: 0.0029\n",
            "precision_at_020: 0.0034\n",
            "precision_at_050: 0.0035\n",
            "precision_at_100: 0.0038\n",
            "r_precision: 0.0023\n",
            "recall_at_005: 0.0001\n",
            "recall_at_010: 0.0004\n",
            "recall_at_020: 0.0025\n",
            "recall_at_050: 0.0037\n",
            "recall_at_100: 0.0183\n",
            "## retrieve_eval img2phrase on train ##\n",
            "mean_average_precision: 0.5924\n",
            "mean_reciprocal_rank: 0.6618\n",
            "precision_at_005: 0.2440\n",
            "precision_at_010: 0.1259\n",
            "precision_at_020: 0.0666\n",
            "precision_at_050: 0.0276\n",
            "precision_at_100: 0.0138\n",
            "r_precision: 0.0021\n",
            "recall_at_005: 0.7816\n",
            "recall_at_010: 0.7982\n",
            "recall_at_020: 0.8275\n",
            "recall_at_050: 0.8507\n",
            "recall_at_100: 0.8519\n",
            "EVAL: since last best: 23\n",
            "STAT pos_dist: shape torch.Size([16]) device cuda:0; mean 10.278; min 7.789; max 15.365; std 1.755\n",
            "STAT neg_img_dist: shape torch.Size([16]) device cuda:0; mean 15.800; min 11.801; max 21.277; std 2.628\n",
            "STAT neg_sent_dist: shape torch.Size([16]) device cuda:0; mean 25.487; min 18.596; max 35.013; std 4.665\n",
            "[02/10 17:10:53] epoch-3 step-650: loss 0.0000 (neg_img: 0.0000, neg_lang: 0.0000); lr 1.0E-07\n",
            "STAT pred_scores: shape torch.Size([432, 655]) device cpu; mean -29.644; min -57.613; max -12.502; std 5.323\n",
            "## retrieve_eval phrase2img on train ##\n",
            "mean_average_precision: 0.0038\n",
            "mean_reciprocal_rank: 0.0044\n",
            "precision_at_005: 0.0024\n",
            "precision_at_010: 0.0029\n",
            "precision_at_020: 0.0034\n",
            "precision_at_050: 0.0036\n",
            "precision_at_100: 0.0038\n",
            "r_precision: 0.0023\n",
            "recall_at_005: 0.0001\n",
            "recall_at_010: 0.0003\n",
            "recall_at_020: 0.0026\n",
            "recall_at_050: 0.0053\n",
            "recall_at_100: 0.0188\n",
            "## retrieve_eval img2phrase on train ##\n",
            "mean_average_precision: 0.5898\n",
            "mean_reciprocal_rank: 0.6601\n",
            "precision_at_005: 0.2444\n",
            "precision_at_010: 0.1262\n",
            "precision_at_020: 0.0666\n",
            "precision_at_050: 0.0276\n",
            "precision_at_100: 0.0138\n",
            "r_precision: 0.0021\n",
            "recall_at_005: 0.7828\n",
            "recall_at_010: 0.7990\n",
            "recall_at_020: 0.8275\n",
            "recall_at_050: 0.8507\n",
            "recall_at_100: 0.8519\n",
            "EVAL: since last best: 24\n",
            "STAT pred_scores: shape torch.Size([432, 655]) device cpu; mean -30.500; min -53.872; max -12.939; std 5.386\n",
            "## retrieve_eval phrase2img on train ##\n",
            "mean_average_precision: 0.0038\n",
            "mean_reciprocal_rank: 0.0035\n",
            "precision_at_005: 0.0021\n",
            "precision_at_010: 0.0027\n",
            "precision_at_020: 0.0036\n",
            "precision_at_050: 0.0036\n",
            "precision_at_100: 0.0038\n",
            "r_precision: 0.0023\n",
            "recall_at_005: 0.0001\n",
            "recall_at_010: 0.0003\n",
            "recall_at_020: 0.0029\n",
            "recall_at_050: 0.0055\n",
            "recall_at_100: 0.0178\n",
            "## retrieve_eval img2phrase on train ##\n",
            "mean_average_precision: 0.5916\n",
            "mean_reciprocal_rank: 0.6602\n",
            "precision_at_005: 0.2449\n",
            "precision_at_010: 0.1257\n",
            "precision_at_020: 0.0664\n",
            "precision_at_050: 0.0276\n",
            "precision_at_100: 0.0138\n",
            "r_precision: 0.0021\n",
            "recall_at_005: 0.7840\n",
            "recall_at_010: 0.7975\n",
            "recall_at_020: 0.8268\n",
            "recall_at_050: 0.8507\n",
            "recall_at_100: 0.8519\n",
            "EVAL: since last best: 25\n",
            "STAT pred_scores: shape torch.Size([432, 655]) device cpu; mean -28.770; min -63.618; max -11.931; std 5.304\n",
            "## retrieve_eval phrase2img on train ##\n",
            "mean_average_precision: 0.0037\n",
            "mean_reciprocal_rank: 0.0047\n",
            "precision_at_005: 0.0024\n",
            "precision_at_010: 0.0031\n",
            "precision_at_020: 0.0034\n",
            "precision_at_050: 0.0035\n",
            "precision_at_100: 0.0037\n",
            "r_precision: 0.0023\n",
            "recall_at_005: 0.0001\n",
            "recall_at_010: 0.0018\n",
            "recall_at_020: 0.0025\n",
            "recall_at_050: 0.0040\n",
            "recall_at_100: 0.0185\n",
            "## retrieve_eval img2phrase on train ##\n",
            "mean_average_precision: 0.5985\n",
            "mean_reciprocal_rank: 0.6666\n",
            "precision_at_005: 0.2435\n",
            "precision_at_010: 0.1259\n",
            "precision_at_020: 0.0666\n",
            "precision_at_050: 0.0276\n",
            "precision_at_100: 0.0138\n",
            "r_precision: 0.0021\n",
            "recall_at_005: 0.7793\n",
            "recall_at_010: 0.7982\n",
            "recall_at_020: 0.8275\n",
            "recall_at_050: 0.8507\n",
            "recall_at_100: 0.8519\n",
            "EVAL: since last best: 26\n",
            "STAT pred_scores: shape torch.Size([432, 655]) device cpu; mean -29.374; min -59.602; max -12.317; std 5.305\n",
            "## retrieve_eval phrase2img on train ##\n",
            "mean_average_precision: 0.0037\n",
            "mean_reciprocal_rank: 0.0044\n",
            "precision_at_005: 0.0021\n",
            "precision_at_010: 0.0027\n",
            "precision_at_020: 0.0034\n",
            "precision_at_050: 0.0034\n",
            "precision_at_100: 0.0037\n",
            "r_precision: 0.0023\n",
            "recall_at_005: 0.0001\n",
            "recall_at_010: 0.0003\n",
            "recall_at_020: 0.0025\n",
            "recall_at_050: 0.0039\n",
            "recall_at_100: 0.0188\n",
            "## retrieve_eval img2phrase on train ##\n",
            "mean_average_precision: 0.5983\n",
            "mean_reciprocal_rank: 0.6665\n",
            "precision_at_005: 0.2449\n",
            "precision_at_010: 0.1259\n",
            "precision_at_020: 0.0666\n",
            "precision_at_050: 0.0276\n",
            "precision_at_100: 0.0138\n",
            "r_precision: 0.0021\n",
            "recall_at_005: 0.7840\n",
            "recall_at_010: 0.7982\n",
            "recall_at_020: 0.8275\n",
            "recall_at_050: 0.8507\n",
            "recall_at_100: 0.8519\n",
            "EVAL: since last best: 27\n",
            "STAT pred_scores: shape torch.Size([432, 655]) device cpu; mean -29.229; min -62.815; max -12.254; std 5.329\n",
            "## retrieve_eval phrase2img on train ##\n",
            "mean_average_precision: 0.0037\n",
            "mean_reciprocal_rank: 0.0044\n",
            "precision_at_005: 0.0027\n",
            "precision_at_010: 0.0026\n",
            "precision_at_020: 0.0034\n",
            "precision_at_050: 0.0035\n",
            "precision_at_100: 0.0037\n",
            "r_precision: 0.0023\n",
            "recall_at_005: 0.0001\n",
            "recall_at_010: 0.0002\n",
            "recall_at_020: 0.0028\n",
            "recall_at_050: 0.0043\n",
            "recall_at_100: 0.0190\n",
            "## retrieve_eval img2phrase on train ##\n",
            "mean_average_precision: 0.5998\n",
            "mean_reciprocal_rank: 0.6680\n",
            "precision_at_005: 0.2444\n",
            "precision_at_010: 0.1259\n",
            "precision_at_020: 0.0666\n",
            "precision_at_050: 0.0276\n",
            "precision_at_100: 0.0138\n",
            "r_precision: 0.0021\n",
            "recall_at_005: 0.7828\n",
            "recall_at_010: 0.7982\n",
            "recall_at_020: 0.8275\n",
            "recall_at_050: 0.8507\n",
            "recall_at_100: 0.8519\n",
            "EVAL: since last best: 28\n",
            "STAT pos_dist: shape torch.Size([16]) device cuda:0; mean 11.233; min 7.889; max 14.912; std 2.087\n",
            "STAT neg_img_dist: shape torch.Size([16]) device cuda:0; mean 18.806; min 14.865; max 25.607; std 2.814\n",
            "STAT neg_sent_dist: shape torch.Size([16]) device cuda:0; mean 24.694; min 16.850; max 30.829; std 4.633\n",
            "[02/10 17:16:33] epoch-4 step-700: loss 0.0000 (neg_img: 0.0000, neg_lang: 0.0000); lr 1.0E-07\n",
            "STAT pred_scores: shape torch.Size([432, 655]) device cpu; mean -29.468; min -50.048; max -12.466; std 5.261\n",
            "## retrieve_eval phrase2img on train ##\n",
            "mean_average_precision: 0.0038\n",
            "mean_reciprocal_rank: 0.0043\n",
            "precision_at_005: 0.0021\n",
            "precision_at_010: 0.0029\n",
            "precision_at_020: 0.0034\n",
            "precision_at_050: 0.0035\n",
            "precision_at_100: 0.0038\n",
            "r_precision: 0.0023\n",
            "recall_at_005: 0.0001\n",
            "recall_at_010: 0.0018\n",
            "recall_at_020: 0.0025\n",
            "recall_at_050: 0.0037\n",
            "recall_at_100: 0.0183\n",
            "## retrieve_eval img2phrase on train ##\n",
            "mean_average_precision: 0.5972\n",
            "mean_reciprocal_rank: 0.6656\n",
            "precision_at_005: 0.2449\n",
            "precision_at_010: 0.1259\n",
            "precision_at_020: 0.0666\n",
            "precision_at_050: 0.0276\n",
            "precision_at_100: 0.0138\n",
            "r_precision: 0.0021\n",
            "recall_at_005: 0.7840\n",
            "recall_at_010: 0.7982\n",
            "recall_at_020: 0.8275\n",
            "recall_at_050: 0.8507\n",
            "recall_at_100: 0.8519\n",
            "EVAL: since last best: 29\n",
            "STAT pred_scores: shape torch.Size([432, 655]) device cpu; mean -30.283; min -58.826; max -12.781; std 5.387\n",
            "## retrieve_eval phrase2img on train ##\n",
            "mean_average_precision: 0.0038\n",
            "mean_reciprocal_rank: 0.0037\n",
            "precision_at_005: 0.0024\n",
            "precision_at_010: 0.0027\n",
            "precision_at_020: 0.0035\n",
            "precision_at_050: 0.0036\n",
            "precision_at_100: 0.0039\n",
            "r_precision: 0.0023\n",
            "recall_at_005: 0.0001\n",
            "recall_at_010: 0.0004\n",
            "recall_at_020: 0.0028\n",
            "recall_at_050: 0.0040\n",
            "recall_at_100: 0.0179\n",
            "## retrieve_eval img2phrase on train ##\n",
            "mean_average_precision: 0.5955\n",
            "mean_reciprocal_rank: 0.6636\n",
            "precision_at_005: 0.2449\n",
            "precision_at_010: 0.1257\n",
            "precision_at_020: 0.0666\n",
            "precision_at_050: 0.0276\n",
            "precision_at_100: 0.0138\n",
            "r_precision: 0.0021\n",
            "recall_at_005: 0.7840\n",
            "recall_at_010: 0.7975\n",
            "recall_at_020: 0.8275\n",
            "recall_at_050: 0.8507\n",
            "recall_at_100: 0.8519\n",
            "EVAL: since last best: 30\n",
            "EVAL: lr decay triggered\n",
            "STAT pred_scores: shape torch.Size([432, 655]) device cpu; mean -29.665; min -63.036; max -12.535; std 5.375\n",
            "## retrieve_eval phrase2img on train ##\n",
            "mean_average_precision: 0.0038\n",
            "mean_reciprocal_rank: 0.0045\n",
            "precision_at_005: 0.0027\n",
            "precision_at_010: 0.0029\n",
            "precision_at_020: 0.0034\n",
            "precision_at_050: 0.0035\n",
            "precision_at_100: 0.0038\n",
            "r_precision: 0.0023\n",
            "recall_at_005: 0.0001\n",
            "recall_at_010: 0.0003\n",
            "recall_at_020: 0.0026\n",
            "recall_at_050: 0.0039\n",
            "recall_at_100: 0.0178\n",
            "## retrieve_eval img2phrase on train ##\n",
            "mean_average_precision: 0.5925\n",
            "mean_reciprocal_rank: 0.6610\n",
            "precision_at_005: 0.2444\n",
            "precision_at_010: 0.1262\n",
            "precision_at_020: 0.0664\n",
            "precision_at_050: 0.0276\n",
            "precision_at_100: 0.0138\n",
            "r_precision: 0.0021\n",
            "recall_at_005: 0.7828\n",
            "recall_at_010: 0.7990\n",
            "recall_at_020: 0.8268\n",
            "recall_at_050: 0.8507\n",
            "recall_at_100: 0.8519\n",
            "EVAL: since last best: 31\n",
            "STAT pred_scores: shape torch.Size([432, 655]) device cpu; mean -29.368; min -55.456; max -12.305; std 5.291\n",
            "## retrieve_eval phrase2img on train ##\n",
            "mean_average_precision: 0.0038\n",
            "mean_reciprocal_rank: 0.0044\n",
            "precision_at_005: 0.0027\n",
            "precision_at_010: 0.0031\n",
            "precision_at_020: 0.0035\n",
            "precision_at_050: 0.0035\n",
            "precision_at_100: 0.0038\n",
            "r_precision: 0.0023\n",
            "recall_at_005: 0.0001\n",
            "recall_at_010: 0.0006\n",
            "recall_at_020: 0.0025\n",
            "recall_at_050: 0.0038\n",
            "recall_at_100: 0.0186\n",
            "## retrieve_eval img2phrase on train ##\n",
            "mean_average_precision: 0.5934\n",
            "mean_reciprocal_rank: 0.6617\n",
            "precision_at_005: 0.2444\n",
            "precision_at_010: 0.1262\n",
            "precision_at_020: 0.0664\n",
            "precision_at_050: 0.0276\n",
            "precision_at_100: 0.0138\n",
            "r_precision: 0.0021\n",
            "recall_at_005: 0.7828\n",
            "recall_at_010: 0.7990\n",
            "recall_at_020: 0.8268\n",
            "recall_at_050: 0.8507\n",
            "recall_at_100: 0.8519\n",
            "EVAL: since last best: 32\n",
            "STAT pos_dist: shape torch.Size([16]) device cuda:0; mean 10.735; min 7.978; max 14.973; std 2.099\n",
            "STAT neg_img_dist: shape torch.Size([16]) device cuda:0; mean 18.308; min 15.556; max 22.572; std 2.136\n",
            "STAT neg_sent_dist: shape torch.Size([16]) device cuda:0; mean 24.528; min 16.362; max 35.122; std 4.428\n",
            "[02/10 17:21:30] epoch-4 step-750: loss 0.0000 (neg_img: 0.0000, neg_lang: 0.0000); lr 1.0E-08\n",
            "STAT pred_scores: shape torch.Size([432, 655]) device cpu; mean -30.005; min -61.245; max -12.757; std 5.381\n",
            "## retrieve_eval phrase2img on train ##\n",
            "mean_average_precision: 0.0038\n",
            "mean_reciprocal_rank: 0.0045\n",
            "precision_at_005: 0.0027\n",
            "precision_at_010: 0.0029\n",
            "precision_at_020: 0.0035\n",
            "precision_at_050: 0.0036\n",
            "precision_at_100: 0.0038\n",
            "r_precision: 0.0023\n",
            "recall_at_005: 0.0001\n",
            "recall_at_010: 0.0018\n",
            "recall_at_020: 0.0025\n",
            "recall_at_050: 0.0040\n",
            "recall_at_100: 0.0182\n",
            "## retrieve_eval img2phrase on train ##\n",
            "mean_average_precision: 0.5920\n",
            "mean_reciprocal_rank: 0.6605\n",
            "precision_at_005: 0.2449\n",
            "precision_at_010: 0.1262\n",
            "precision_at_020: 0.0666\n",
            "precision_at_050: 0.0276\n",
            "precision_at_100: 0.0138\n",
            "r_precision: 0.0021\n",
            "recall_at_005: 0.7840\n",
            "recall_at_010: 0.7990\n",
            "recall_at_020: 0.8275\n",
            "recall_at_050: 0.8507\n",
            "recall_at_100: 0.8519\n",
            "EVAL: since last best: 33\n",
            "STAT pred_scores: shape torch.Size([432, 655]) device cpu; mean -28.998; min -63.010; max -12.225; std 5.307\n",
            "## retrieve_eval phrase2img on train ##\n",
            "mean_average_precision: 0.0038\n",
            "mean_reciprocal_rank: 0.0044\n",
            "precision_at_005: 0.0027\n",
            "precision_at_010: 0.0029\n",
            "precision_at_020: 0.0034\n",
            "precision_at_050: 0.0036\n",
            "precision_at_100: 0.0038\n",
            "r_precision: 0.0023\n",
            "recall_at_005: 0.0001\n",
            "recall_at_010: 0.0002\n",
            "recall_at_020: 0.0025\n",
            "recall_at_050: 0.0052\n",
            "recall_at_100: 0.0186\n",
            "## retrieve_eval img2phrase on train ##\n",
            "mean_average_precision: 0.5976\n",
            "mean_reciprocal_rank: 0.6652\n",
            "precision_at_005: 0.2440\n",
            "precision_at_010: 0.1259\n",
            "precision_at_020: 0.0666\n",
            "precision_at_050: 0.0276\n",
            "precision_at_100: 0.0138\n",
            "r_precision: 0.0021\n",
            "recall_at_005: 0.7816\n",
            "recall_at_010: 0.7982\n",
            "recall_at_020: 0.8275\n",
            "recall_at_050: 0.8507\n",
            "recall_at_100: 0.8519\n",
            "EVAL: since last best: 34\n",
            "STAT pred_scores: shape torch.Size([432, 655]) device cpu; mean -29.478; min -57.294; max -12.434; std 5.300\n",
            "## retrieve_eval phrase2img on train ##\n",
            "mean_average_precision: 0.0038\n",
            "mean_reciprocal_rank: 0.0045\n",
            "precision_at_005: 0.0027\n",
            "precision_at_010: 0.0031\n",
            "precision_at_020: 0.0033\n",
            "precision_at_050: 0.0036\n",
            "precision_at_100: 0.0038\n",
            "r_precision: 0.0023\n",
            "recall_at_005: 0.0001\n",
            "recall_at_010: 0.0006\n",
            "recall_at_020: 0.0025\n",
            "recall_at_050: 0.0055\n",
            "recall_at_100: 0.0183\n",
            "## retrieve_eval img2phrase on train ##\n",
            "mean_average_precision: 0.5934\n",
            "mean_reciprocal_rank: 0.6617\n",
            "precision_at_005: 0.2449\n",
            "precision_at_010: 0.1259\n",
            "precision_at_020: 0.0666\n",
            "precision_at_050: 0.0276\n",
            "precision_at_100: 0.0138\n",
            "r_precision: 0.0021\n",
            "recall_at_005: 0.7840\n",
            "recall_at_010: 0.7982\n",
            "recall_at_020: 0.8275\n",
            "recall_at_050: 0.8507\n",
            "recall_at_100: 0.8519\n",
            "EVAL: since last best: 35\n",
            "STAT pred_scores: shape torch.Size([432, 655]) device cpu; mean -29.938; min -63.123; max -12.678; std 5.394\n",
            "## retrieve_eval phrase2img on train ##\n",
            "mean_average_precision: 0.0037\n",
            "mean_reciprocal_rank: 0.0044\n",
            "precision_at_005: 0.0024\n",
            "precision_at_010: 0.0024\n",
            "precision_at_020: 0.0032\n",
            "precision_at_050: 0.0035\n",
            "precision_at_100: 0.0038\n",
            "r_precision: 0.0023\n",
            "recall_at_005: 0.0001\n",
            "recall_at_010: 0.0002\n",
            "recall_at_020: 0.0025\n",
            "recall_at_050: 0.0037\n",
            "recall_at_100: 0.0188\n",
            "## retrieve_eval img2phrase on train ##\n",
            "mean_average_precision: 0.5927\n",
            "mean_reciprocal_rank: 0.6607\n",
            "precision_at_005: 0.2449\n",
            "precision_at_010: 0.1259\n",
            "precision_at_020: 0.0664\n",
            "precision_at_050: 0.0276\n",
            "precision_at_100: 0.0138\n",
            "r_precision: 0.0021\n",
            "recall_at_005: 0.7840\n",
            "recall_at_010: 0.7982\n",
            "recall_at_020: 0.8268\n",
            "recall_at_050: 0.8507\n",
            "recall_at_100: 0.8519\n",
            "EVAL: since last best: 36\n",
            "STAT pos_dist: shape torch.Size([16]) device cuda:0; mean 10.616; min 6.831; max 13.154; std 1.791\n",
            "STAT neg_img_dist: shape torch.Size([16]) device cuda:0; mean 15.983; min 13.012; max 19.397; std 1.866\n",
            "STAT neg_sent_dist: shape torch.Size([16]) device cuda:0; mean 25.204; min 20.313; max 36.226; std 4.387\n",
            "[02/10 17:26:27] epoch-4 step-800: loss 0.0000 (neg_img: 0.0000, neg_lang: 0.0000); lr 1.0E-08\n",
            "STAT pred_scores: shape torch.Size([432, 655]) device cpu; mean -29.753; min -57.883; max -12.495; std 5.328\n",
            "## retrieve_eval phrase2img on train ##\n",
            "mean_average_precision: 0.0038\n",
            "mean_reciprocal_rank: 0.0044\n",
            "precision_at_005: 0.0027\n",
            "precision_at_010: 0.0027\n",
            "precision_at_020: 0.0034\n",
            "precision_at_050: 0.0035\n",
            "precision_at_100: 0.0038\n",
            "r_precision: 0.0023\n",
            "recall_at_005: 0.0001\n",
            "recall_at_010: 0.0004\n",
            "recall_at_020: 0.0025\n",
            "recall_at_050: 0.0041\n",
            "recall_at_100: 0.0186\n",
            "## retrieve_eval img2phrase on train ##\n",
            "mean_average_precision: 0.5978\n",
            "mean_reciprocal_rank: 0.6657\n",
            "precision_at_005: 0.2449\n",
            "precision_at_010: 0.1259\n",
            "precision_at_020: 0.0666\n",
            "precision_at_050: 0.0276\n",
            "precision_at_100: 0.0138\n",
            "r_precision: 0.0021\n",
            "recall_at_005: 0.7840\n",
            "recall_at_010: 0.7982\n",
            "recall_at_020: 0.8275\n",
            "recall_at_050: 0.8507\n",
            "recall_at_100: 0.8519\n",
            "EVAL: since last best: 37\n",
            "STAT pred_scores: shape torch.Size([432, 655]) device cpu; mean -29.690; min -60.918; max -12.514; std 5.349\n",
            "## retrieve_eval phrase2img on train ##\n",
            "mean_average_precision: 0.0038\n",
            "mean_reciprocal_rank: 0.0044\n",
            "precision_at_005: 0.0027\n",
            "precision_at_010: 0.0027\n",
            "precision_at_020: 0.0034\n",
            "precision_at_050: 0.0035\n",
            "precision_at_100: 0.0038\n",
            "r_precision: 0.0023\n",
            "recall_at_005: 0.0001\n",
            "recall_at_010: 0.0002\n",
            "recall_at_020: 0.0025\n",
            "recall_at_050: 0.0039\n",
            "recall_at_100: 0.0187\n",
            "## retrieve_eval img2phrase on train ##\n",
            "mean_average_precision: 0.5971\n",
            "mean_reciprocal_rank: 0.6646\n",
            "precision_at_005: 0.2449\n",
            "precision_at_010: 0.1257\n",
            "precision_at_020: 0.0666\n",
            "precision_at_050: 0.0276\n",
            "precision_at_100: 0.0138\n",
            "r_precision: 0.0021\n",
            "recall_at_005: 0.7840\n",
            "recall_at_010: 0.7975\n",
            "recall_at_020: 0.8275\n",
            "recall_at_050: 0.8507\n",
            "recall_at_100: 0.8519\n",
            "EVAL: since last best: 38\n",
            "STAT pred_scores: shape torch.Size([432, 655]) device cpu; mean -28.843; min -68.947; max -12.080; std 5.378\n",
            "## retrieve_eval phrase2img on train ##\n",
            "mean_average_precision: 0.0038\n",
            "mean_reciprocal_rank: 0.0046\n",
            "precision_at_005: 0.0031\n",
            "precision_at_010: 0.0026\n",
            "precision_at_020: 0.0034\n",
            "precision_at_050: 0.0035\n",
            "precision_at_100: 0.0038\n",
            "r_precision: 0.0023\n",
            "recall_at_005: 0.0001\n",
            "recall_at_010: 0.0002\n",
            "recall_at_020: 0.0025\n",
            "recall_at_050: 0.0037\n",
            "recall_at_100: 0.0184\n",
            "## retrieve_eval img2phrase on train ##\n",
            "mean_average_precision: 0.6013\n",
            "mean_reciprocal_rank: 0.6685\n",
            "precision_at_005: 0.2435\n",
            "precision_at_010: 0.1259\n",
            "precision_at_020: 0.0666\n",
            "precision_at_050: 0.0276\n",
            "precision_at_100: 0.0138\n",
            "r_precision: 0.0021\n",
            "recall_at_005: 0.7793\n",
            "recall_at_010: 0.7982\n",
            "recall_at_020: 0.8275\n",
            "recall_at_050: 0.8507\n",
            "recall_at_100: 0.8519\n",
            "EVAL: since last best: 39\n",
            "STAT pred_scores: shape torch.Size([432, 655]) device cpu; mean -29.558; min -65.149; max -12.488; std 5.384\n",
            "## retrieve_eval phrase2img on train ##\n",
            "mean_average_precision: 0.0038\n",
            "mean_reciprocal_rank: 0.0044\n",
            "precision_at_005: 0.0027\n",
            "precision_at_010: 0.0027\n",
            "precision_at_020: 0.0034\n",
            "precision_at_050: 0.0035\n",
            "precision_at_100: 0.0038\n",
            "r_precision: 0.0023\n",
            "recall_at_005: 0.0001\n",
            "recall_at_010: 0.0004\n",
            "recall_at_020: 0.0026\n",
            "recall_at_050: 0.0037\n",
            "recall_at_100: 0.0186\n",
            "## retrieve_eval img2phrase on train ##\n",
            "mean_average_precision: 0.5965\n",
            "mean_reciprocal_rank: 0.6641\n",
            "precision_at_005: 0.2444\n",
            "precision_at_010: 0.1259\n",
            "precision_at_020: 0.0666\n",
            "precision_at_050: 0.0276\n",
            "precision_at_100: 0.0138\n",
            "r_precision: 0.0021\n",
            "recall_at_005: 0.7828\n",
            "recall_at_010: 0.7982\n",
            "recall_at_020: 0.8275\n",
            "recall_at_050: 0.8507\n",
            "recall_at_100: 0.8519\n",
            "EVAL: since last best: 40\n",
            "EVAL: lr decay triggered\n",
            "EVAL: early stop triggered\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# After Replacing BEST_checkpoint.pth Train DomainToText_AMLProject"
      ],
      "metadata": {
        "id": "dRNVsLdAi9O_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Moving to folder DomainToText_AMLProject"
      ],
      "metadata": {
        "id": "1L3vP_E1gIRd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#cd ../../DomainToText_AMLProject/"
      ],
      "metadata": {
        "id": "ney_jhwCpwrT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to replace \"BEST_checkpoint.pth\" file or alternatively we can pass path of \"BEST_checkpoint.pth\" in our eval_ensamble.py file."
      ],
      "metadata": {
        "id": "dkJfxo6wyORJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python eval_ensamble.py --path_to_txt \"./data/PACS\" --target \"ArtPainting\""
      ],
      "metadata": {
        "id": "KLU0sBws0USI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04c8417b-467c-40e8-e1c0-b7b6f1e6536f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(gpu=0, num_classes=7, path_to_dataset='./', path_to_txt='./data/PACS', target='ArtPainting')\n",
            "äsdasfs\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Sources Cartoon, Photo, Sketch\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100% 44.7M/44.7M [00:00<00:00, 179MB/s]\n",
            "Model of Cartoon loaded \n",
            "Model of Photo loaded \n",
            "Model of Sketch loaded \n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Model pretrained on Textures loaded\n",
            "100% 2344/2344 [05:07<00:00,  7.62it/s]\n",
            "100% 1670/1670 [03:26<00:00,  8.08it/s]\n",
            "100% 3929/3929 [08:09<00:00,  8.02it/s]\n",
            "Evaluation on the Target domain - ArtPainting\n",
            "100% 2048/2048 [04:40<00:00,  7.31it/s]\n",
            "Accuracy mean: 67.63 \n",
            "Accuracy text_domain_embedding: 68.70 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python eval_ensamble.py --path_to_txt \"./data/PACS\" --target \"Cartoon\""
      ],
      "metadata": {
        "id": "9mIJspyDjXwd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b6e371b-bf30-4c5a-f37c-4962928d9ec3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(gpu=0, num_classes=7, path_to_dataset='./', path_to_txt='./data/PACS', target='Cartoon')\n",
            "äsdasfs\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Sources ArtPainting, Photo, Sketch\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100% 44.7M/44.7M [00:04<00:00, 10.9MB/s]\n",
            "Model of ArtPainting loaded \n",
            "Model of Photo loaded \n",
            "Model of Sketch loaded \n",
            "Downloading: \"https://download.pytorch.org/models/resnet101-63fe2227.pth\" to /root/.cache/torch/hub/checkpoints/resnet101-63fe2227.pth\n",
            "100% 171M/171M [00:01<00:00, 97.9MB/s]\n",
            "Downloading: 100% 226k/226k [00:00<00:00, 312kB/s]\n",
            "Downloading: 100% 28.0/28.0 [00:00<00:00, 22.5kB/s]\n",
            "Downloading: 100% 455k/455k [00:00<00:00, 510kB/s]\n",
            "Downloading: 100% 570/570 [00:00<00:00, 434kB/s]\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/configuration_utils.py:337: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
            "  \"Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 \"\n",
            "Downloading: 100% 420M/420M [00:09<00:00, 44.1MB/s]\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Model pretrained on Textures loaded\n",
            "100% 2048/2048 [06:32<00:00,  5.21it/s]\n",
            "100% 1670/1670 [06:18<00:00,  4.41it/s]\n",
            "100% 3929/3929 [12:34<00:00,  5.21it/s]\n",
            "Evaluation on the Target domain - Cartoon\n",
            "100% 2344/2344 [06:16<00:00,  6.23it/s]\n",
            "Accuracy mean: 57.12 \n",
            "Accuracy text_domain_embedding: 57.17 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python eval_ensamble.py --path_to_txt \"./data/PACS\" --target \"Photo\""
      ],
      "metadata": {
        "id": "QNP_GWTYjcEC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ffcaa00-447c-427b-85bf-5b324b55e118"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(gpu=0, num_classes=7, path_to_dataset='./', path_to_txt='./data/PACS', target='Photo')\n",
            "äsdasfs\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Sources ArtPainting, Cartoon, Sketch\n",
            "Model of ArtPainting loaded \n",
            "Model of Cartoon loaded \n",
            "Model of Sketch loaded \n",
            "/usr/local/lib/python3.7/dist-packages/transformers/configuration_utils.py:337: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
            "  \"Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 \"\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Model pretrained on Textures loaded\n",
            "100% 2048/2048 [01:52<00:00, 18.17it/s]\n",
            "100% 2344/2344 [02:09<00:00, 18.09it/s]\n",
            "100% 3929/3929 [03:34<00:00, 18.29it/s]\n",
            "Evaluation on the Target domain - Photo\n",
            "100% 1670/1670 [02:41<00:00, 10.37it/s]\n",
            "Accuracy mean: 94.49 \n",
            "Accuracy text_domain_embedding: 94.61 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python eval_ensamble.py --path_to_txt \"./data/PACS\" --target \"Sketch\""
      ],
      "metadata": {
        "id": "pdV2S2BOjewq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbaa02ef-3453-47e4-ff06-647d22a0da44"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(gpu=0, num_classes=7, path_to_dataset='./', path_to_txt='./data/PACS', target='Sketch')\n",
            "äsdasfs\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Sources ArtPainting, Cartoon, Photo\n",
            "Model of ArtPainting loaded \n",
            "Model of Cartoon loaded \n",
            "Model of Photo loaded \n",
            "/usr/local/lib/python3.7/dist-packages/transformers/configuration_utils.py:337: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
            "  \"Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 \"\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Model pretrained on Textures loaded\n",
            "100% 2048/2048 [01:51<00:00, 18.39it/s]\n",
            "100% 2344/2344 [02:11<00:00, 17.83it/s]\n",
            "100% 1670/1670 [01:32<00:00, 17.98it/s]\n",
            "Evaluation on the Target domain - Sketch\n",
            "100% 3929/3929 [06:19<00:00, 10.37it/s]\n",
            "Accuracy mean: 60.40 \n",
            "Accuracy text_domain_embedding: 60.58 \n"
          ]
        }
      ]
    }
  ]
}